{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "06/03/21_verynice_working_now_march.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TIMEdilation584/JP_Loksatta_moving_hearts/blob/master/06_03_21_verynice_working_now_march.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05KTXP7XoABy"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stpqi6N6oC4Q",
        "outputId": "4a5341a7-229f-452a-8413-ac722f1eef00"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztrS-_z9nr42",
        "outputId": "163fcc01-6719-456f-c9eb-90ccf5a0392b"
      },
      "source": [
        "import cv2\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from glob import glob\n",
        "import IPython.display as display\n",
        "from IPython.display import clear_output\n",
        "from google.colab import files\n",
        "import math\n",
        "import time\n",
        "from tensorflow.keras.layers import *\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# For more information about autotune:\n",
        "# https://www.tensorflow.org/guide/data_performance#prefetching\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "print(f'Tensorflow ver. {tf.__version__}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow ver. 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hWkxIiNkqXKE",
        "outputId": "d625dbfe-33fc-403c-8618-19e2322aa560"
      },
      "source": [
        "#cd .."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsHopd_8nr49"
      },
      "source": [
        "# important for reproducibility\n",
        "# this allows to generate the same random numbers\n",
        "SEED = 42\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = 'drive/My Drive/idd-lite/idd20k_lite/'\n",
        "img_train = dataset_path + 'leftImg8bit/train/'\n",
        "seg_train = dataset_path + 'gtFine/train/'\n",
        "\n",
        "img_val = dataset_path + 'leftImg8bit/val/'\n",
        "seg_val = dataset_path + 'gtFine/val/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6mOJGr-Iy1Rk"
      },
      "source": [
        "def parse_image(img_path):\n",
        "    \"\"\"\n",
        "    Load an image and its annotation (mask) and returning a dictionary.\n",
        "    \"\"\"\n",
        "    # Reading the image\n",
        "    image = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    # For one Image path:\n",
        "    # .../idd20k_lite/leftImg8bit/train/024541_image.jpg\n",
        "    # Its corresponding annotation path is:\n",
        "    # .../idd20k_lite/gtFine/train/024541_label.png\n",
        "    mask_path = tf.strings.regex_replace(img_path, \"leftImg8bit\", \"gtFine\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"_image.jpg\", \"_label.png\")\n",
        "    # Reading the annotation file corresponding the image file\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    # In scene parsing, \"not labeled\" = 255\n",
        "    # But it will mess with our N_CLASS = 7\n",
        "    # Since 255 means the 255th class\n",
        "    # Which doesn't exist\n",
        "    mask = tf.where(mask==255, np.dtype('uint8').type(7), mask)\n",
        "    # Note that we have to convert the new value (7)\n",
        "    # With the same dtype than the tensor itself\n",
        "    return {'image': image, 'segmentation_mask': mask}\n",
        "\n",
        "def normalize(input_image, input_mask):\n",
        "    \"\"\"\n",
        "    Rescale the pixel values of the images between 0 and 1 compared to [0,255] originally.\n",
        "    \"\"\"\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_image_train(datapoint):\n",
        "    \"\"\"\n",
        "    Normalize and resize a train image and its annotation.\n",
        "    Apply random transformations to an input dictionary containing a train image and its annotation.\n",
        "    \"\"\"\n",
        "    input_image = tf.image.resize(datapoint['image'], (128,128))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (128,128))\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_image_test(datapoint):\n",
        "    \"\"\"\n",
        "    Normalize and resize a test image and its annotation.\n",
        "    Since this is for the test set, we don't need to apply any data augmentation technique.\n",
        "    \"\"\"\n",
        "    input_image = tf.image.resize(datapoint['image'], (128,128))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (128,128))\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask\n",
        "\n",
        "def display_sample(display_list):\n",
        "    \"\"\"\n",
        "    Show side-by-side an input image,\n",
        "    the ground truth and the prediction.\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15,15))\n",
        "    title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
        "    for i in range(len(display_list)):\n",
        "        plt.subplot(1, len(display_list), i+1)\n",
        "        plt.title(title[i])\n",
        "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
        "        plt.axis('off')\n",
        "    plt.show()\n",
        "    \n",
        "def predict(model,image_path,single_image):\n",
        "    \"\"\"\n",
        "    This function will take the model which is going to be used to predict the image and the image path of \n",
        "    the input image as inputs and predict the mask\n",
        "    It returns the true mask and predicted mask\n",
        "    \"\"\"\n",
        "    # Getting the datapoint\n",
        "    # This function will load the image and its annotation (mask) and return a dictionary.\n",
        "    datapoint = parse_image(image_path)\n",
        "    # Normalizing the resizing the datapoint\n",
        "    input_image,image_mask = load_image_test(datapoint)\n",
        "    # As the model takes input with 4 dimensions (batch_size, rows, columns, channels),\n",
        "    # and the shape of the input image is (rows, columns, channels)\n",
        "    # we will expand the first dimension so we will get the shape as  (1, rows, columns, channels)\n",
        "    img = tf.expand_dims(input_image, 0)\n",
        "    # Predicting the image by passing it to the model\n",
        "    prediction = model(img)\n",
        "    # The model will predict 8 outputs for each pixel\n",
        "    # We have to get the maximum value out of it\n",
        "    prediction = tf.argmax(prediction, axis=-1)\n",
        "    prediction = tf.squeeze(prediction, axis = 0)\n",
        "    pred_mask = tf.expand_dims(prediction, axis=-1)\n",
        "    # Displaying the input image, true mask, predicted mask\n",
        "    if(single_image):\n",
        "        display_sample([input_image, image_mask, pred_mask])\n",
        "    return image_mask, pred_mask\n",
        "\n",
        "def IoU(y_i,y_pred):\n",
        "    # This function calculates the mean Intersection over Union\n",
        "    # Mean IoU = TP/(FN + TP + FP)\n",
        "    # This list will save the IoU of all the classes\n",
        "    IoUs = []\n",
        "    # Defining the number of classes which the model has predicted\n",
        "    n_classes = 8\n",
        "    for c in range(n_classes):\n",
        "        # Calculating the True Positives\n",
        "        TP = np.sum((y_i == c)&(y_pred==c))\n",
        "        # Calculating the False Positives\n",
        "        FP = np.sum((y_i != c)&(y_pred==c))\n",
        "        # Calculating the False Negatives\n",
        "        FN = np.sum((y_i == c)&(y_pred!= c))\n",
        "        # Calculating the IoU for the particular class\n",
        "        IoU = TP/float(TP + FP + FN)\n",
        "        # Printing the outputs\n",
        "        # Uncomment the print statement below when you want to analyze the results for each class\n",
        "        print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\".format(c,TP,FP,FN,IoU))\n",
        "        # Appending the IoU to the list as it mean needs to be calculated later\n",
        "        if(math.isnan(IoU)):\n",
        "            IoUs.append(0)\n",
        "            continue\n",
        "        IoUs.append(IoU)\n",
        "    # Calculating the mean\n",
        "    mIoU = np.mean(IoUs)\n",
        "    #print(\"_________________\")\n",
        "    #print(\"Mean IoU: {:4.3f}\".format(mIoU))\n",
        "    return mIoU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqeyQl-hy1Rn"
      },
      "source": [
        "# A class to get the basic convolution block \n",
        "# convolution_layer -> batch_normalization -> activation\n",
        "class BasicConvolutionBlock(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, filter_size, kernel_size, dilation_rate, alpha, block_number, initializer='he_normal'):\n",
        "        super(BasicConvolutionBlock, self).__init__()\n",
        "        # block_number variable is used to keep a track of blocks as the structure changes slightly for 3rd and 4th block\n",
        "        self.block_number = block_number\n",
        "        # defining a convolution layer\n",
        "        self.convolution_layer = Convolution2D(filter_size, kernel_size =  kernel_size, \n",
        "                                               dilation_rate = dilation_rate, padding = 'same',\n",
        "                                               kernel_initializer = initializer)\n",
        "        # defining a batch normalization layer\n",
        "        self.batch_normalization = BatchNormalization()\n",
        "        # defining a LeakyReLU activation layer\n",
        "        self.activation = LeakyReLU(alpha = alpha)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # getting the convolution output\n",
        "        conv_output = self.convolution_layer(inputs)\n",
        "        # normalizaing the convolution output\n",
        "        norm_output = self.batch_normalization(conv_output)\n",
        "        # for 3rd block and 4th block, we return the normalized output without activation layer\n",
        "        if(self.block_number >= 3):\n",
        "            return norm_output\n",
        "        # Passing the normalized output through LeakyReLU\n",
        "        activation_output = self.activation(norm_output)  \n",
        "        return activation_output\n",
        "\n",
        "# A Building Block of Residual Network\n",
        "class ConvolutionBlock(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, filters, initializer='he_normal'):     \n",
        "        super(ConvolutionBlock, self).__init__()\n",
        "        # The filters will be a list with 3 filter sizes (eg. [32,32,64]) where each filter size \n",
        "        # will be passed to a BasicConvolutionBlock\n",
        "        self.filters = filters\n",
        "        # Defining basic convolution blocks for each filter size\n",
        "        self.basic_convolution_1 = BasicConvolutionBlock(self.filters[0], (1,1), (1,1), 0.2, 1)\n",
        "        self.basic_convolution_2 = BasicConvolutionBlock(self.filters[1], (3,3), (2,2), 0.2, 2)\n",
        "        self.basic_convolution_3 = BasicConvolutionBlock(self.filters[2], (1,1), (1,1), None, 3)\n",
        "        # Defining the skip connection that is used in Residual BLocks\n",
        "        self.skip_convolution = BasicConvolutionBlock(self.filters[2], (3,3), (1,1), None, 4)\n",
        "        # Last Block\n",
        "        self.add_layer = Add()\n",
        "        self.relu_activation = ReLU()\n",
        "     \n",
        "    def call(self, inputs):\n",
        "        # Getting the skip input\n",
        "        skip_input = inputs\n",
        "        # Getting the convolution outputs from BasicConvolutionBlocks\n",
        "        output_conv_1 = self.basic_convolution_1(inputs)\n",
        "        output_conv_2 = self.basic_convolution_2(output_conv_1)\n",
        "        output_conv_3 = self.basic_convolution_3(output_conv_2)\n",
        "        output_skip_conv = self.skip_convolution(skip_input)\n",
        "        # Last Block\n",
        "        # Adding the skip connection output and output of last convolution block\n",
        "        add_output = self.add_layer([output_conv_3,output_skip_conv])\n",
        "        # Passing the added output through ReLU activation\n",
        "        output = self.relu_activation(add_output)\n",
        "        return output\n",
        "\n",
        "# Encoder block for PSPNet\n",
        "class EncoderBlock(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, filters):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        # filters -> [[32,32,64],[64,64,128],[128,128,256],[256,256,512]]\n",
        "        # Each sublist in the abover filters list will be passed to ConvolutionBlocks\n",
        "        # and every single element in the sublist will be further passed to BasicConvolutionBlock\n",
        "        self.filters = filters\n",
        "        # Defining the convolution blocks\n",
        "        self.convolution_block_1 = ConvolutionBlock(self.filters[0])\n",
        "        self.convolution_block_2 = ConvolutionBlock(self.filters[1])\n",
        "        self.convolution_block_3 = ConvolutionBlock(self.filters[2])\n",
        "        self.convolution_block_4 = ConvolutionBlock(self.filters[3])\n",
        "        \n",
        "    def call(self, inputs):     \n",
        "        # Passing the inputs to the Convolution Block defined above\n",
        "        output_block_1 = self.convolution_block_1(inputs)\n",
        "        # Passing the output of convolution blocks to futher convolution blocks\n",
        "        output_block_2 = self.convolution_block_2(output_block_1)\n",
        "        output_block_3 = self.convolution_block_3(output_block_2) \n",
        "        output_block_4 = self.convolution_block_4(output_block_3)\n",
        "        return output_block_4\n",
        "    \n",
        "# This class returns the pyramid feature map for Pyramid Pooling module\n",
        "# Pooling -> Convolution -> UpSampling\n",
        "class PyramidFeatureMap(tf.keras.Model): \n",
        "    \n",
        "    def __init__(self, block, filter_size, unsampling_size, pool_size, interpolation='bilinear'):\n",
        "        super(PyramidFeatureMap, self).__init__()\n",
        "        # There are 4 blocks -> red, yellow, blue, green\n",
        "        # As the pooling technique is different for Red block, defining a block will help\n",
        "        # to keep a track of the changes that are required for different blocks\n",
        "        self.block = block\n",
        "        # Defining the convolution layer\n",
        "        self.convolution_layer = Convolution2D(filter_size, kernel_size = (1,1))\n",
        "        # Defining the UpSampling layer\n",
        "        self.upsampling_layer = UpSampling2D(unsampling_size, interpolation = interpolation)\n",
        "        # Defining the average pooling layer that is going to be used for yellow, blue and green\n",
        "        self.average_pooling = AveragePooling2D(pool_size)\n",
        "        # Defining a global average pooling layer for red block\n",
        "        self.global_average_pooling = GlobalAveragePooling2D()\n",
        "        \n",
        "    def call(self,inputs):\n",
        "        # For Red block, we will pass the input through GlobalAveragePooling layer\n",
        "        if(self.block=='red'):\n",
        "            pool_output = self.global_average_pooling(inputs)\n",
        "            pool_output = Reshape((1,1,512))(pool_output)\n",
        "        # For all the other blocks, we will perform AveragePooling\n",
        "        else:\n",
        "            pool_output = self.average_pooling(inputs)\n",
        "        # Passing the pooled output through convolution layer\n",
        "        conv_output = self.convolution_layer(pool_output)\n",
        "        # Passing the convolution output through UpSampling layer\n",
        "        upsampling_output = self.upsampling_layer(conv_output)\n",
        "        return upsampling_output        \n",
        "    \n",
        "# This class builds the Pyramid Pooling Module\n",
        "# It builds the 4 feature maps and then concatenates all of them with the input\n",
        "class PyramidPoolingModule(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(PyramidPoolingModule, self).__init__()\n",
        "        # Defining the PyramidFeatureMaps for red, yellow, blue and green blocks along with the\n",
        "        # filter_size, unsampling_size and pool_size\n",
        "        self.block_red = PyramidFeatureMap('red', 64, (128,128), (1,1))\n",
        "        self.block_yellow = PyramidFeatureMap('yellow', 64, 2, (2,2))\n",
        "        self.block_blue = PyramidFeatureMap('blue', 64, 4, (4,4))\n",
        "        self.block_green = PyramidFeatureMap('green', 64, 8, (8,8))\n",
        "        \n",
        "    def call(self,inputs):\n",
        "        # Passing the inputs through each of the blocks\n",
        "        red_output = self.block_red(inputs)\n",
        "        yellow_output = self.block_yellow(inputs)\n",
        "        blue_output = self.block_blue(inputs)\n",
        "        green_output = self.block_green(inputs)\n",
        "        # Concatenating the inputs with the outputs of each of the PyramidFeatureMaps\n",
        "        merged = concatenate([inputs, red_output, yellow_output, blue_output, green_output])\n",
        "        return merged  \n",
        "\n",
        "# This block is for the last stage\n",
        "# It gets the output of Pyramid Pooling Module and then performs convolution operation\n",
        "# Pyramid Pooling Module -> Convolution -> Batch Normalization -> Softmax activation\n",
        "class DecoderBlock(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        # Defining the PyramidPoolingModule\n",
        "        self.pyramid_pooling_module = PyramidPoolingModule()\n",
        "        # Defining the Convolution Layer with filter size as number of classes\n",
        "        self.convolution_layer = Convolution2D(num_classes, kernel_size = (3,3), padding = 'same')\n",
        "        # Defining the BatchNormalization layer\n",
        "        self.batch_norm_layer = BatchNormalization()\n",
        "        # Defining the last softmax activation layer\n",
        "        self.activation = Activation('softmax')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        # Getting the PyramidPoolingModule output\n",
        "        merged = self.pyramid_pooling_module(inputs)\n",
        "        # Passing the PyramidPoolingModule output to ConvolutionLayer\n",
        "        conv_output = self.convolution_layer(merged)\n",
        "        # Passing the convolution output to BatchNormalization layer\n",
        "        norm_output = self.batch_norm_layer(conv_output)\n",
        "        # Passing the normalized output through activation layer\n",
        "        output = self.activation(norm_output)\n",
        "        return output\n",
        "\n",
        "#This final class for the Model\n",
        "class PSPNetModel(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super(PSPNetModel, self).__init__()\n",
        "        # Defining the Encoder block with lists of filter sizes for ConvolutionBlocks\n",
        "        self.encoder = EncoderBlock([[32,32,64],[64,64,128],[128,128,256],[256,256,512]])\n",
        "        # Defining the Decoder blocks\n",
        "        self.decoder = DecoderBlock(num_classes)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        # Passing the inputs through Encoder Blocks\n",
        "        encoder_output = self.encoder(inputs)\n",
        "        # Passing the encoder output through decoder block\n",
        "        final_output = self.decoder(encoder_output)\n",
        "        return final_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_d3E5y9by1Rp"
      },
      "source": [
        "def PipeLine(dataset_path, img_train, seg_train, img_val, seg_val):\n",
        "    start = time.time()\n",
        "    print(\"Data preparation...\\n\")\n",
        "    N_CLASSES = 8\n",
        "    TRAINSET_SIZE = len(glob(img_train+'*/*_image.jpg'))\n",
        "    VALSET_SIZE = len(glob(img_val+'*/*_image.jpg'))\n",
        "    train_dataset = tf.data.Dataset.list_files(img_train+'*/*_image.jpg', seed=SEED)\n",
        "    train_dataset = train_dataset.map(parse_image)\n",
        "    val_dataset = tf.data.Dataset.list_files(img_val+'*/*_image.jpg', seed=SEED)\n",
        "    val_dataset = val_dataset.map(parse_image)\n",
        "    BATCH_SIZE = 8\n",
        "    BUFFER_SIZE = 1500\n",
        "    dataset = {\"train\": train_dataset, \"val\": val_dataset}\n",
        "    dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
        "    dataset['train'] = dataset['train'].repeat()\n",
        "    dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
        "    dataset['train'] = dataset['train'].prefetch(buffer_size=AUTOTUNE)\n",
        "    print(\"Train Dataset : \",dataset['train'])\n",
        "    dataset['val'] = dataset['val'].map(load_image_test)\n",
        "    dataset['val'] = dataset['val'].repeat()\n",
        "    dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
        "    dataset['val'] = dataset['val'].prefetch(buffer_size=AUTOTUNE)\n",
        "    print(\"Validation Dataset : \",dataset['val'])\n",
        "    print(\"\\nDone with data preparation.\\n\")\n",
        "    print(\"Model Building...\\n\")\n",
        "    model = PSPNetModel(N_CLASSES)\n",
        "    model.build(input_shape=(None,128,128,3))\n",
        "    print(\"Loading the best weights...\\n\")\n",
        "    model.load_weights('drive/My Drive/pspnet_weights-epoch-46.hdf5')\n",
        "    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
        "    for (x_train, y_train) in dataset['train'].take(math.ceil(1403/8)):\n",
        "        predictions = model(x_train, training=True)\n",
        "        train_accuracy(y_train, predictions)\n",
        "    print(\"Train accuracy = \",train_accuracy.result().numpy()*100)\n",
        "    val_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('val_accuracy')\n",
        "    for (x_val, y_val) in dataset['val'].take(math.ceil(1403/8)):\n",
        "        predictions = model(x_val, training=True)\n",
        "        val_accuracy(y_val, predictions)\n",
        "    print(\"\\nValidation accuracy = \",val_accuracy.result().numpy()*100)\n",
        "    print(\"\\nVisualizing predictions for a single validation image..\\n\")\n",
        "    true_mask, pred_mask = predict(model,'drive/My Drive/AppliedAICaseStudies/SemanticSegmentation/idd20k_lite/leftImg8bit/val/21/240284_image.jpg',True)\n",
        "    print(\"\\nIoU Calculation for Sample Image = \\n\")\n",
        "    mIoU = IoU(true_mask, pred_mask)\n",
        "    print(\"\\nMean Intersection over union for example image : \",mIoU)\n",
        "    print(\"\\nTime taken = \",time.time()-start)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 613
        },
        "id": "paj9HiKSy1Rs",
        "outputId": "9db25b33-28a7-49fe-bf30-c30fa0062c90"
      },
      "source": [
        "PipeLine(dataset_path, img_train, seg_train, img_val, seg_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data preparation...\n",
            "\n",
            "Train Dataset :  <PrefetchDataset shapes: ((None, 128, 128, 3), (None, 128, 128, 1)), types: (tf.float32, tf.float32)>\n",
            "Validation Dataset :  <PrefetchDataset shapes: ((None, 128, 128, 3), (None, 128, 128, 1)), types: (tf.float32, tf.float32)>\n",
            "\n",
            "Done with data preparation.\n",
            "\n",
            "Model Building...\n",
            "\n",
            "Loading the best weights...\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-7d2adde941b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mPipeLine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseg_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-7-871b5761623a>\u001b[0m in \u001b[0;36mPipeLine\u001b[0;34m(dataset_path, img_train, seg_train, img_val, seg_val)\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loading the best weights...\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 30\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'drive/My Drive/pspnet_weights-epoch-46.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     31\u001b[0m     \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mceil\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1403\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2225\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2226\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2227\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2228\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2229\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'drive/My Drive/pspnet_weights-epoch-46.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n6AFGKWDq37y",
        "outputId": "953490ef-afaf-45b2-81d2-c00d6d21bad3"
      },
      "source": [
        "ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mgtFine\u001b[0m/  \u001b[01;34mimages\u001b[0m/  \u001b[01;34mlabels\u001b[0m/  \u001b[01;34mleftImg8bit\u001b[0m/  \u001b[01;34mtrain\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2oEHewcq9D-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}