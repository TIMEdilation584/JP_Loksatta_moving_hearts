{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPyITID5KkOF5rQvuRv1dU6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TIMEdilation584/JP_Loksatta_moving_hearts/blob/master/ELMO%20for%20text%20classification%20April%2019%202022.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 496
        },
        "id": "c9N36fKB9DwO",
        "outputId": "9fa4ada2-2a62-44f2-8c7b-4d797a3031be"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-438433412c49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_pro\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_data_and_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mData\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mopt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# -*- coding: utf-8 -*-\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElmo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_to_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from data_pro import load_data_and_labels, Data\n",
        "from model import Model\n",
        "from config import opt\n",
        "\n",
        "\n",
        "def now():\n",
        "    return str(time.strftime('%Y-%m-%d %H:%M:%S'))\n",
        "\n",
        "\n",
        "def collate_fn(batch):\n",
        "    data, label = zip(*batch)\n",
        "    return data, label\n",
        "\n",
        "\n",
        "def train(**kwargs):\n",
        "\n",
        "    opt.parse(kwargs)\n",
        "    device = torch.device(\"cuda:{}\".format(opt.gpu_id) if torch.cuda.is_available() else \"cpu\")\n",
        "    opt.device = device\n",
        "\n",
        "    random.seed(opt.seed)\n",
        "    np.random.seed(opt.seed)\n",
        "    torch.manual_seed(opt.seed)\n",
        "    if opt.use_gpu:\n",
        "        torch.cuda.manual_seed_all(opt.seed)\n",
        "\n",
        "    x_text, y = load_data_and_labels(\"./data/rt-polarity.pos\", \"./data/rt-polarity.neg\")\n",
        "    x_train, x_test, y_train, y_test = train_test_split(x_text, y, test_size=opt.test_size)\n",
        "\n",
        "    train_data = Data(x_train, y_train)\n",
        "    test_data = Data(x_test, y_test)\n",
        "    train_loader = DataLoader(train_data, batch_size=opt.batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "    test_loader = DataLoader(test_data, batch_size=opt.batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    print(f\"{now()} train data: {len(train_data)}, test data: {len(test_data)}\")\n",
        "\n",
        "    model = Model(opt)\n",
        "    print(f\"{now()} {opt.emb_method} init model finished\")\n",
        "\n",
        "    if opt.use_gpu:\n",
        "        model.to(device)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=opt.lr, weight_decay=opt.weight_decay)\n",
        "    lr_sheduler = optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.7)\n",
        "    best_acc = -0.1\n",
        "    best_epoch = -1\n",
        "    start_time = time.time()\n",
        "    for epoch in range(1, opt.epochs):\n",
        "        total_loss = 0.0\n",
        "        model.train()\n",
        "        for step, batch_data in enumerate(train_loader):\n",
        "            x, labels = batch_data\n",
        "            labels = torch.LongTensor(labels)\n",
        "            if opt.use_gpu:\n",
        "                labels = labels.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output = model(x)\n",
        "            loss = criterion(output, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "        acc = test(model, test_loader)\n",
        "        if acc > best_acc:\n",
        "            best_acc = acc\n",
        "            best_epoch = epoch\n",
        "        print(f\"{now()} Epoch{epoch}: loss: {total_loss}, test_acc: {acc}\")\n",
        "        lr_sheduler.step()\n",
        "\n",
        "    end_time = time.time()\n",
        "    print(\"*\"*20)\n",
        "    print(f\"{now()} finished; epoch {best_epoch} best_acc: {best_acc}, time/epoch: {(end_time-start_time)/opt.epochs}\")\n",
        "\n",
        "\n",
        "def test(model, test_loader):\n",
        "    correct = 0\n",
        "    num = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for data in test_loader:\n",
        "            x, labels = data\n",
        "            num += len(labels)\n",
        "            output = model(x)\n",
        "            labels = torch.LongTensor(labels)\n",
        "            if opt.use_gpu:\n",
        "                output = output.cpu()\n",
        "            predict = torch.max(output.data, 1)[1]\n",
        "            correct += (predict == labels).sum().item()\n",
        "    model.train()\n",
        "    return correct * 1.0 / num\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import fire\n",
        "    fire.Fire()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, enc_method, input_size, hidden_size, out_size):\n",
        "        '''\n",
        "        input_size\n",
        "        hidden_size: the output size of CNN/RNN/TR\n",
        "        outpu_size: the final size of the encoder (after pooling)\n",
        "        w\n",
        "        CNN:\n",
        "        - filters_num: feature_dim\n",
        "        - filter_size: 3\n",
        "        - pooling: max_pooling\n",
        "        RNN:\n",
        "        - hidden_size: feature_dim // 2\n",
        "        - pooling: last hidden status\n",
        "        Transformer\n",
        "        - nhead: 2\n",
        "        - nlayer: 1\n",
        "        - pooling: average\n",
        "        -------\n",
        "        '''\n",
        "        super(Encoder, self).__init__()\n",
        "        self.enc_method = enc_method.lower()\n",
        "        if self.enc_method == 'cnn':\n",
        "            self.conv = nn.Conv2d(1, hidden_size, (3, input_size))\n",
        "            nn.init.xavier_uniform_(self.conv.weight)\n",
        "            nn.init.constant_(self.conv.bias, 0.0)\n",
        "            f_dim = hidden_size\n",
        "        elif self.enc_method == 'rnn':\n",
        "            self.rnn = nn.GRU(input_size, hidden_size//2, batch_first=True, bidirectional=True)\n",
        "            f_dim = hidden_size\n",
        "        elif self.enc_method == 'transformer':\n",
        "            self.pe = PositionEmbedding(input_size, 512)\n",
        "            self.layer = nn.TransformerEncoderLayer(d_model=input_size, nhead=1)\n",
        "            self.tr = nn.TransformerEncoder(self.layer, num_layers=1)\n",
        "            f_dim = input_size\n",
        "        else:\n",
        "            f_dim = input_size\n",
        "\n",
        "        self.fc = nn.Linear(f_dim, out_size)\n",
        "        nn.init.uniform_(self.fc.weight, -0.5, 0.5)\n",
        "        nn.init.uniform_(self.fc.bias, -0.1, 0.1)\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if self.enc_method == 'cnn':\n",
        "            x = inputs.unsqueeze(1)\n",
        "            x = F.relu(self.conv(x).squeeze(3))\n",
        "            out = x.permute(0, 2, 1)\n",
        "        elif self.enc_method == 'rnn':\n",
        "            out, _ = self.rnn(inputs)\n",
        "        elif self.enc_method == 'transformer':\n",
        "            inputs = self.pe(inputs)\n",
        "            out = self.tr(inputs.permute(1, 0, 2)).permute(1, 0, 2)\n",
        "        else:\n",
        "            out = inputs\n",
        "        return self.fc(out.mean(1))\n",
        "\n",
        "\n",
        "class PositionEmbedding(nn.Module):\n",
        "    def __init__(self, d_model, max_len):\n",
        "        super(PositionEmbedding, self).__init__()\n",
        "        self.pe = nn.Embedding(max_len, d_model)\n",
        "        nn.init.uniform_(self.pe.weight, -0.1, 0.1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        b, l, d = x.size()\n",
        "        seq_len = torch.arange(l).to(x.device)\n",
        "        return x + self.pe(seq_len).unsqueeze(0)\n",
        "\n",
        "\n",
        "# performance poor\n",
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, d_model, max_len):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        pe = torch.zeros(max_len, d_model)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0)\n",
        "        self.register_buffer('pe', pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[:, :x.size(1)]\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "dfqTpBDZ9jcU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from allennlp.modules.elmo import Elmo, batch_to_ids\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoModel, AutoTokenizer\n",
        "import numpy as np\n",
        "\n",
        "from encoder import Encoder\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, opt):\n",
        "\n",
        "        super(Model, self).__init__()\n",
        "        self.opt = opt\n",
        "        self.use_gpu = self.opt.use_gpu\n",
        "\n",
        "        if opt.emb_method == 'elmo':\n",
        "            self.init_elmo()\n",
        "        elif self.opt.emb_method == 'glove':\n",
        "            self.init_glove()\n",
        "        elif self.opt.emb_method == 'bert':\n",
        "            self.init_bert()\n",
        "\n",
        "        self.encoder = Encoder(opt.enc_method, self.word_dim, opt.hidden_size, opt.out_size)\n",
        "        self.cls = nn.Linear(opt.out_size, opt.num_labels)\n",
        "        nn.init.uniform_(self.cls.weight, -0.1, 0.1)\n",
        "        nn.init.uniform_(self.cls.bias, -0.1, 0.1)\n",
        "        self.dropout = nn.Dropout(self.opt.dropout)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.opt.emb_method == 'elmo':\n",
        "            word_embs = self.get_elmo(x)\n",
        "        elif self.opt.emb_method == 'glove':\n",
        "            word_embs = self.get_glove(x)\n",
        "        elif self.opt.emb_method == 'bert':\n",
        "            word_embs = self.get_bert(x)\n",
        "\n",
        "        x = self.encoder(word_embs)\n",
        "        x = self.dropout(x)\n",
        "        x = self.cls(x)    # batch_size * num_label\n",
        "        return x\n",
        "\n",
        "    def init_bert(self):\n",
        "        '''\n",
        "        initilize the Bert model\n",
        "        '''\n",
        "        self.bert_tokenizer = AutoTokenizer.from_pretrained(self.opt.bert_path)\n",
        "        self.bert = AutoModel.from_pretrained(self.opt.bert_path)\n",
        "        for param in self.bert.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.word_dim = self.opt.bert_dim\n",
        "\n",
        "    def init_elmo(self):\n",
        "        '''\n",
        "        initilize the ELMo model\n",
        "        '''\n",
        "        self.elmo = Elmo(self.opt.elmo_options_file, self.opt.elmo_weight_file, 1)\n",
        "        for param in self.elmo.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.word_dim = self.opt.elmo_dim\n",
        "\n",
        "    def init_glove(self):\n",
        "        '''\n",
        "        load the GloVe model\n",
        "        '''\n",
        "        self.word2id = np.load(self.opt.word2id_file, allow_pickle=True).tolist()\n",
        "        self.glove = nn.Embedding(self.opt.vocab_size, self.opt.glove_dim)\n",
        "        emb = torch.from_numpy(np.load(self.opt.glove_file, allow_pickle=True))\n",
        "        if self.use_gpu:\n",
        "            emb = emb.to(self.opt.device)\n",
        "        self.glove.weight.data.copy_(emb)\n",
        "        self.word_dim = self.opt.glove_dim\n",
        "\n",
        "    def get_bert(self, sentence_lists):\n",
        "        '''\n",
        "        get the ELMo word embedding vectors for a sentences\n",
        "        '''\n",
        "        sentence_lists = [' '.join(x) for x in sentence_lists]\n",
        "        ids = self.bert_tokenizer(sentence_lists, padding=True, return_tensors=\"pt\")\n",
        "        inputs = ids['input_ids']\n",
        "        if self.opt.use_gpu:\n",
        "            inputs = inputs.to(self.opt.device)\n",
        "\n",
        "        embeddings = self.bert(inputs)\n",
        "        return embeddings[0]\n",
        "\n",
        "    def get_elmo(self, sentence_lists):\n",
        "        '''\n",
        "        get the ELMo word embedding vectors for a sentences\n",
        "        '''\n",
        "        character_ids = batch_to_ids(sentence_lists)\n",
        "        if self.opt.use_gpu:\n",
        "            character_ids = character_ids.to(self.opt.device)\n",
        "        embeddings = self.elmo(character_ids)\n",
        "        return embeddings['elmo_representations'][0]\n",
        "\n",
        "    def get_glove(self, sentence_lists):\n",
        "        '''\n",
        "        get the glove word embedding vectors for a sentences\n",
        "        '''\n",
        "        max_len = max(map(lambda x: len(x), sentence_lists))\n",
        "        sentence_lists = list(map(lambda x: list(map(lambda w: self.word2id.get(w, 0), x)), sentence_lists))\n",
        "        sentence_lists = list(map(lambda x: x + [self.opt.vocab_size-1] * (max_len - len(x)), sentence_lists))\n",
        "        sentence_lists = torch.LongTensor(sentence_lists)\n",
        "        if self.use_gpu:\n",
        "            sentence_lists = sentence_lists.to(self.opt.device)\n",
        "        embeddings = self.glove(sentence_lists)\n",
        "\n",
        "        return embeddings\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "ME2L_3lJ9Xrn",
        "outputId": "327bbd50-c8b1-483e-fa2a-06c3290aa6d8"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-b515c9291ceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElmo\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_to_ids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAutoModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python main.py train --emb_method='elmo' --enc_method='cnn'\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 131
        },
        "id": "_ZKgoBhT-x_X",
        "outputId": "cb8e8ddf-167b-41c0-b4fd-810202b3eff6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-13-1be01556d1ae>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    python main.py train --emb_method='elmo' --enc_method='cnn'\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import re\n",
        "import os\n",
        "import sys\n",
        "import numpy as np\n",
        "import pickle\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "\n",
        "\n",
        "class Data(Dataset):\n",
        "    def __init__(self, x, y):\n",
        "        self.data = list(zip(x, y))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        assert idx < len(self)\n",
        "        return self.data[idx]\n",
        "\n",
        "\n",
        "def clean_str(string):\n",
        "    \"\"\"\n",
        "    Tokenization/string cleaning for all datasets except for SST.\n",
        "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
        "    \"\"\"\n",
        "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
        "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
        "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
        "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
        "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
        "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
        "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
        "    string = re.sub(r\",\", \" , \", string)\n",
        "    string = re.sub(r\"!\", \" ! \", string)\n",
        "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
        "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
        "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
        "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
        "    return string.strip().lower()\n",
        "\n",
        "\n",
        "def extract_vocab(positive_data_file, negative_data_file):\n",
        "    '''\n",
        "    extract vocab from txt\n",
        "    '''\n",
        "    positive_examples = list(open(positive_data_file, \"r\", encoding='utf-8').readlines())\n",
        "    positive_examples = [s.strip() for s in positive_examples]\n",
        "    negative_examples = list(open(negative_data_file, \"r\", encoding='utf-8').readlines())\n",
        "    negative_examples = [s.strip() for s in negative_examples]\n",
        "    x_text = positive_examples + negative_examples\n",
        "    x_text = [clean_str(sent) for sent in x_text]\n",
        "    x_text = list(map(lambda x: x.split(), x_text))\n",
        "\n",
        "    vocab = []\n",
        "    for line in x_text:\n",
        "        vocab.extend(line)\n",
        "\n",
        "    vocab = list(set(vocab))\n",
        "    print(\"vocab size: {}.\".format(len(vocab)))\n",
        "    open(\"./data/glove/vocab.txt\", \"w\").write(\"\\n\".join(vocab))\n",
        "\n",
        "\n",
        "def get_glove(w2v_path, vocab_path):\n",
        "\n",
        "    vocab = {j.strip(): i for i, j in enumerate(open(vocab_path), 0)}\n",
        "    id2word = {vocab[i]: i for i in vocab}\n",
        "\n",
        "    dim = 0\n",
        "    w2v = {}\n",
        "    for line in open(w2v_path):\n",
        "        line = line.strip().split()\n",
        "        word = line[0]\n",
        "        vec = list(map(float, line[1:]))\n",
        "        dim = len(vec)\n",
        "        w2v[word] = vec\n",
        "\n",
        "    vecs = []\n",
        "    vecs.append(np.random.uniform(low=-1.0, high=1.0, size=dim))\n",
        "\n",
        "    hit = 0\n",
        "    for i in range(1, len(vocab) - 1):\n",
        "        if id2word[i] in w2v:\n",
        "            hit += 1\n",
        "            vecs.append(w2v[id2word[i]])\n",
        "        else:\n",
        "            vecs.append(vecs[0])\n",
        "    vecs.append(np.zeros(dim))\n",
        "    assert(len(vecs) == len(vocab))\n",
        "\n",
        "    print(\"vocab size: {}, dim: {}; hit in glove:{}\".format(len(vocab), dim, hit))\n",
        "    np.save(\"./data/glove/glove_{}d.npy\".format(dim), np.array(vecs, dtype=np.float32))\n",
        "    np.save(\"./data/glove/word2id.npy\", vocab)\n",
        "    np.save(\"./data/glove/id2word.npy\", id2word)\n",
        "\n",
        "\n",
        "def load_data_and_labels(positive_data_file, negative_data_file):\n",
        "    \"\"\"\n",
        "    Loads MR polarity data from files, splits the data into words and generates labels.\n",
        "    Returns split sentences and labels.\n",
        "    \"\"\"\n",
        "    # Load data from files\n",
        "    positive_examples = list(open(positive_data_file, \"r\", encoding='utf-8').readlines())\n",
        "    positive_examples = [s.strip() for s in positive_examples]\n",
        "    negative_examples = list(open(negative_data_file, \"r\", encoding='utf-8').readlines())\n",
        "    negative_examples = [s.strip() for s in negative_examples]\n",
        "    # Split by words\n",
        "    x_text = positive_examples + negative_examples\n",
        "    x_text = [clean_str(sent) for sent in x_text]\n",
        "    x_text = list(map(lambda x: x.split(), x_text))\n",
        "    # Generate labels\n",
        "    positive_labels = [1 for _ in positive_examples]\n",
        "    negative_labels = [0 for _ in negative_examples]\n",
        "    y = np.array(positive_labels + negative_labels)\n",
        "    return [x_text, y]\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    import fire\n",
        "    fire.Fire()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "CY1pm0Ao9tyq",
        "outputId": "84b07162-7073-4d3f-c311-a9e1607d5460"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-43285db2da6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m     \u001b[0;32mimport\u001b[0m \u001b[0mfire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m     \u001b[0mfire\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'fire'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "class Config():\n",
        "\n",
        "    # ELMo\n",
        "    elmo_options_file = \"./data/elmo/elmo_2x2048_256_2048cnn_1xhighway_options.json\"\n",
        "    elmo_weight_file = \"./data/elmo/elmo_2x2048_256_2048cnn_1xhighway_weights.hdf5\"\n",
        "    elmo_dim = 512\n",
        "\n",
        "    # Bert\n",
        "    bert_path = './data/bert/'\n",
        "    bert_dim = 768\n",
        "\n",
        "    # glove\n",
        "    vocab_size = 18766\n",
        "    glove_dim = 300\n",
        "    glove_file = \"./data/glove/glove_300d.npy\"\n",
        "    word2id_file = \"./data/glove/word2id.npy\"\n",
        "\n",
        "    emb_method = 'glove'  # bert/elmo/glove/\n",
        "    enc_method = 'CNN'  # CNN/RNN/Transformer/mean\n",
        "    hidden_size = 200\n",
        "    out_size = 64\n",
        "    num_labels = 2\n",
        "\n",
        "    use_gpu = True\n",
        "    seed = 2020\n",
        "    gpu_id = 0\n",
        "\n",
        "    dropout = 0.5\n",
        "    epochs = 20\n",
        "\n",
        "    test_size = 0.1\n",
        "    lr = 1e-3\n",
        "    weight_decay = 1e-4\n",
        "    batch_size = 64\n",
        "    device = \"cuda:0\"\n",
        "\n",
        "\n",
        "def parse(self, kwargs):\n",
        "    '''\n",
        "    user can update the default hyperparamter\n",
        "    '''\n",
        "    for k, v in kwargs.items():\n",
        "        if not hasattr(self, k):\n",
        "            raise Exception('opt has No key: {}'.format(k))\n",
        "        setattr(self, k, v)\n",
        "\n",
        "    print('*************************************************')\n",
        "    print('user config:')\n",
        "    for k, v in self.__class__.__dict__.items():\n",
        "        if not k.startswith('__'):\n",
        "            print(\"{} => {}\".format(k, getattr(self, k)))\n",
        "\n",
        "    print('*************************************************')\n",
        "\n",
        "\n",
        "Config.parse = parse\n",
        "opt = Config()"
      ],
      "metadata": {
        "id": "tDJZJTsN9z-w"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from allennlp.commands.elmo import ElmoEmbedder\n",
        "import numpy as np\n",
        "\n",
        "#define max token length\n",
        "max_tokens=60\n",
        "\n",
        "#input sentences\n",
        "sentences=[\"how are you doing\",\"what is your name\",\"can you subscribe to my channel\"]\n",
        "\n",
        "#create a pretrained elmo model (requires internet connection)\n",
        "elmo = ElmoEmbedder(cuda_device=0)\n",
        "embeddings=[]\n",
        "\n",
        "#loop through the input sentences\n",
        "for index,elmo_embedding in enumerate(elmo.embed_sentences(sentences)):  \n",
        "    print(\"elmo:\",index)\n",
        "    # Average the 3 layers returned from Elmo\n",
        "    avg_elmo_embedding = np.average(elmo_embedding, axis=0)\n",
        "    padding_length = max_tokens - avg_elmo_embedding.shape[0]\n",
        "    if(padding_length>0):\n",
        "        avg_elmo_embedding =np.append(avg_elmo_embedding, np.zeros((padding_length, avg_elmo_embedding.shape[1])), axis=0)\n",
        "    else:\n",
        "        avg_elmo_embedding=avg_elmo_embedding[:max_tokens]\n",
        "    embeddings.append(avg_elmo_embedding) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 375
        },
        "id": "IV-6pcj7-axk",
        "outputId": "f2e0097f-a351-4d4e-fe0d-83a8057228b7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-5f302d61974c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mallennlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melmo\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElmoEmbedder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m#define max token length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'allennlp'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "i3ZZ-LXA90pB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}