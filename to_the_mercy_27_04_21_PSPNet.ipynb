{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "PSPNet.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TIMEdilation584/JP_Loksatta_moving_hearts/blob/master/to_the_mercy_27_04_21_PSPNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05KTXP7XoABy"
      },
      "source": [
        "%tensorflow_version 2.x"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Stpqi6N6oC4Q",
        "outputId": "72083d5d-7b38-42a8-8983-9d9a7f26b00b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ztrS-_z9nr42",
        "outputId": "d1788a1a-7455-4513-94ee-ad4d72bec170"
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from glob import glob\n",
        "import IPython.display as display\n",
        "from IPython.display import clear_output\n",
        "import math\n",
        "import time\n",
        "from tensorflow.keras.layers import *\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# For more information about autotune:\n",
        "# https://www.tensorflow.org/guide/data_performance#prefetching\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "print(f'Tensorflow ver. {tf.__version__}')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow ver. 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlQWmSTdnr48"
      },
      "source": [
        "## Loading the Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsHopd_8nr49"
      },
      "source": [
        "# important for reproducibility\n",
        "# this allows to generate the same random numbers\n",
        "SEED = 42\n",
        "\n",
        "# Dataset path\n",
        "dataset_path = 'drive/My Drive/idd-lite/idd20k_lite/'\n",
        "img_train = dataset_path + 'leftImg8bit/train/'\n",
        "seg_train = dataset_path + 'gtFine/train/'\n",
        "\n",
        "img_val = dataset_path + 'leftImg8bit/val/'\n",
        "seg_val = dataset_path + 'gtFine/val/'"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQcL7PtTAflr",
        "outputId": "b640206f-0673-446c-a763-0d1295de379f"
      },
      "source": [
        "dataset_path = 'drive/My Drive/idd-lite/idd20k_lite/'\n",
        "img_train = dataset_path + 'leftImg8bit/train/'\n",
        "glob(img_train+'*/*_image.jpg')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/333/frame2417_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/333/frame0731_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/316/frame3750_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/316/frame12094_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/316/frame23904_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/316/frame11820_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/316/frame20123_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/311/frame4439_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/311/frame2189_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/018539_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/003246_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/025743_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/020395_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/021791_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/021198_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/018974_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/018809_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/025972_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/018614_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/003486_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/020455_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/018929_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/52/003366_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/137/821878_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/137/916150_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/137/125388_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/137/440778_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/223/frame7444_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/223/frame4349_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/453/0006335_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/453/0012054_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/453/0008680_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/453/0011806_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/453/0012289_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/453/0013240_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/453/0003540_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/453/0004695_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/220/frame0009_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/95/354004_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/95/940205_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/95/662718_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/95/488144_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/95/496780_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/95/501062_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/95/943609_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/95/349346_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/433/frame1289_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/433/frame1859_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/433/frame7289_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/207/frame7284_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/207/frame2680_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/268/frame5844_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/268/frame20289_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/268/frame17078_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/268/frame24568_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/268/frame8624_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/268/frame34536_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/268/frame23262_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/238/frame0009_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/90/226576_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/90/107267_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/90/226734_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/90/109188_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/421715_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/835381_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/420156_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/828496_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/838879_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/771493_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/970497_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/838963_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/022873_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/750720_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/260366_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/155/310144_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/493/0000704_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/483/frame14917_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/483/frame9707_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/483/frame16558_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/483/frame2390_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/483/frame12693_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/483/frame9781_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/483/frame12580_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/483/frame12664_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/483/frame6832_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/483/frame5684_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/483/frame2685_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/547/0001033_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/547/0002418_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/547/0002331_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/547/0000822_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0023892_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0025961_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0023711_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0041079_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0026793_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0022311_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0001440_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0031362_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0029056_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0029661_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0043118_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0016056_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0015823_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0014868_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0034112_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0022659_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0002929_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0021314_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0006329_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0004919_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/548/0014281_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/301/frame0659_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/269/frame1799_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/472/frame60267_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/472/frame34862_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/472/frame59844_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/472/frame24567_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/472/frame45253_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/472/frame3339_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/472/frame0992_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/131/433054_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/131/547407_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/131/729168_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/131/049769_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/131/493184_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/131/674792_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/131/878528_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/465/0001055_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/42/571609_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/42/634443_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/42/956443_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/42/574289_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/42/845231_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/42/633455_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/130/007329_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/130/019239_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame55835_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame62926_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame2973_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame25017_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame48526_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame60308_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame42444_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame58999_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame13126_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame33962_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame30520_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame37044_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame61917_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/338/frame28284_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/127/238425_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/127/674919_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/127/185379_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/127/047230_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/127/840288_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/448/frame2129_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/728500_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/870698_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/856978_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/101972_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/104884_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/507521_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/861890_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/525378_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/567438_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/507085_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/126888_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/130727_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/94/614500_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/218/frame5725_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/138/027135_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/138/017127_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/138/006445_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/138/020026_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/138/005845_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/26/699848_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/168/218225_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/168/174666_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/168/511497_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/168/237399_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/168/579123_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/001541_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/012093_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/022216_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/021466_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/004636_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/008572_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/021106_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/013895_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/011797_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/007987_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/026656_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/36/022201_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/91/658903_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/91/875048_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/91/423204_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/91/568006_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/280/frame1249_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/280/frame4424_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/108/119180_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/108/676673_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/108/430763_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/108/431932_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/104/209186_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/104/374126_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/104/563753_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/104/156670_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/104/705435_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/104/176225_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/11/489340_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/11/416335_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/11/112144_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/11/411206_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/449/frame1634_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/449/frame2054_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/505/frame27653_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/353/frame8607_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/353/frame27137_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame0648_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame8914_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame27244_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame19794_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame0367_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame5924_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame5266_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame4384_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame11406_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame27442_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame18703_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame16210_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame17423_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame16388_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame6386_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/252/frame18009_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/243/frame6989_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/243/frame2999_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/243/frame0719_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/502/frame5014_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/502/frame27003_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/502/frame106813_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/502/frame104100_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/502/frame77158_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/502/frame45812_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/502/frame9994_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/502/frame11358_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/502/frame18658_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/502/frame10085_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/361/frame5872_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/361/frame12101_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/361/frame7402_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/550/0000502_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/87/029585_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/87/357164_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/87/376124_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/87/391435_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/87/371008_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/87/292116_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/87/293374_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/87/367805_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/87/702328_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/556/frame0134_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/556/frame4394_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/152/030890_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/152/016207_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/152/973352_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/152/034149_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/152/762387_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/152/635556_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/464/frame0239_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/528/frame1409_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/23/396198_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/23/528598_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/23/824708_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/23/871675_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/23/533768_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/23/592149_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/23/061239_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/23/594781_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/23/065223_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/23/928063_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/457/frame2099_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame3039_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame15499_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame57935_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame20380_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame37917_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame12117_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame46835_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame50680_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame24635_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame13344_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame23435_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame40726_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame4299_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame0329_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame43508_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame4989_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame76071_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame13180_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame45608_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame29817_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame39471_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame26571_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame11899_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame12226_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame62626_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame5409_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame31562_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame16126_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame55262_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame73344_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame36826_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame0599_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame2469_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame9971_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame54744_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/377/frame26162_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/173/091944_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/173/711209_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/173/692692_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/173/246109_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/81/790330_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/81/916102_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/81/680622_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/81/235184_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/121/726004_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/121/939431_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/121/501242_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/121/239132_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/121/348149_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/121/888058_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/121/375280_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/121/488582_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/177/027279_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/177/013616_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/177/004655_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/174/917959_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/174/056653_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/174/472135_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/174/925386_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/174/046338_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/174/603456_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/174/531264_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/174/159952_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame0724_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame71226_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame5584_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame10158_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame60408_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame10612_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame0524_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame53249_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame67544_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame2459_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame73453_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame50612_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame6434_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame7434_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame5184_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/237/frame64408_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/498/frame4198_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/498/frame4069_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/498/frame13617_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/498/frame19044_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/498/frame19944_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/498/frame5100_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/498/frame11830_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/39/513939_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/39/048798_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/520/frame1184_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/157/998984_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/157/247569_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/157/213930_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/157/063690_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/157/668203_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/157/798023_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/157/219212_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/157/217050_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/70/477753_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/70/104856_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/70/630264_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/70/587361_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/70/643798_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/70/130351_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/70/759400_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/70/262555_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/70/964837_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/70/971263_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/400/frame3849_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/299/frame0419_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/146/000624_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/146/000963_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/231/frame11708_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/356745_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/023213_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/200483_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/000497_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/411406_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/448339_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/495487_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/994530_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/648444_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/236264_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/404782_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/151/799360_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/351/frame3846_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/59/114277_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/59/578996_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/59/407095_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/59/338479_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/59/652560_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/59/197688_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/59/531483_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/106/344832_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/106/960225_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/106/577732_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/561/0000367_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/370/frame1321_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/125/148536_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/125/891407_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/125/346636_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/125/223851_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/38/001077_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/170/962933_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/170/899943_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/170/743853_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/100/635804_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/100/711957_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/100/296819_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/100/521867_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/100/675055_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/100/975841_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/100/206998_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/100/178149_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/257/frame0119_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/419/frame0092_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/419/frame2789_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/325/frame0479_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/325/frame0239_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/124/809168_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/124/350940_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/124/208276_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/367/frame0011_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/577/frame24835_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/128/313135_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/128/806657_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/163/274338_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/163/678833_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/163/098983_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/530/frame2187_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/387/frame0074_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/387/frame3393_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/387/frame5161_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/334/frame2127_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/334/frame3567_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/334/frame1647_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/334/frame3897_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/354/frame0373_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/160/302487_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/160/304836_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/160/440293_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/406/frame2129_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/406/frame1709_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/355/frame5774_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/355/frame1827_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/564/frame1409_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/416/0001924_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/416/0003613_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/416/0006371_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/126/546479_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/126/125671_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/126/124352_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/417/0020462_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/417/0020794_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/417/0008799_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/417/0004398_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/417/0019370_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/417/0019674_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/417/0018578_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/402/frame17135_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/402/frame4091_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/409/frame1739_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/409/frame0359_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/529/frame8459_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/529/frame8804_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/438/frame0022_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/551/frame7540_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/551/frame35599_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/373/frame3010_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/64/752501_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/64/404847_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/64/408519_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/178/140567_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/178/759395_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/178/696836_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/178/331473_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/178/162616_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/178/103331_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/178/105033_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/178/873503_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/410/frame1364_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/68/009976_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/68/019576_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/68/015676_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/68/014476_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/68/006553_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/68/010576_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/37/016164_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/37/017729_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/37/025983_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/37/019366_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/37/021823_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/37/016066_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/37/019666_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/266/frame11844_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/266/frame11108_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/266/frame11653_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/266/frame5798_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/266/frame9218_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/266/frame8978_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/277/frame3254_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/277/frame21717_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/277/frame8084_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/277/frame19180_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/277/frame3974_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/277/frame18280_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/277/frame17299_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/79/015074_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/79/012790_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/79/013186_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/79/027076_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/503/frame10917_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/503/frame13099_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/265/frame2282_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/340/frame0434_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/340/frame0014_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/340/frame2264_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/225/frame0005_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/204/frame15700_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/204/frame15891_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/204/frame10573_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/204/frame6227_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/204/frame8297_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/204/frame4067_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/204/frame8657_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/303/frame4259_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/317/frame1340_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/525/0003356_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/525/0000446_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/525/0002471_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/235/frame9991_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/235/frame7116_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/235/frame6691_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/235/frame9445_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/235/frame11618_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/336/frame1754_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/432/frame19899_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/432/frame14053_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/432/frame12380_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/45/068732_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/45/792210_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/45/793684_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/45/943824_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/45/073777_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/86/030853_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/86/217562_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/206/frame0008_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/554/frame2516_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/554/frame21739_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/230/frame66316_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/230/frame15457_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/230/frame5258_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/230/frame92404_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/230/frame2075_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/230/frame62989_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/230/frame10278_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/230/frame22282_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/230/frame80370_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/339/frame1722_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/375/frame4589_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/375/frame9899_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/375/frame9329_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/375/frame1769_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/375/frame7499_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/414/frame80453_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/414/frame73067_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/414/frame75180_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/53/098951_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/53/783565_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/53/122196_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/53/412120_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/53/904080_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/53/566200_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/53/971359_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/513/frame1379_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/261/frame4559_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/261/frame8729_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/261/frame6749_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/261/frame7859_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/209/frame8362_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/209/frame0252_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/209/frame8122_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/209/frame2692_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/806231_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/443193_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/890423_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/766332_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/649255_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/810276_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/650232_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/144547_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/394101_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/090616_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/770286_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/228360_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/162836_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/456511_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/355117_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/917332_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/811686_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/96/189474_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/306/frame2351_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/306/frame4703_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/306/frame4849_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/306/frame3347_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/306/frame6330_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/469/frame12021_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/469/frame0224_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/236/frame38217_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/236/frame41599_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/236/frame33308_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/260/frame0390_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/501/frame3028_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/56/770605_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/56/329610_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/56/606044_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/423/frame8397_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/162/979223_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/162/554318_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/162/597145_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/162/705452_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/162/888262_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/477/frame0160_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/359/frame1952_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/437/frame13108_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/478/frame0839_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/543/frame6745_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/543/frame5345_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/201/frame2519_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame78544_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame18499_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame83817_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame31112_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame44544_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame20476_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame47294_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame25885_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame78180_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame26635_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame45953_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame47612_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame86749_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame36408_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame32408_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame21658_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame81180_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/439/frame20771_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/429/frame13262_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/452/0000540_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/452/0004023_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/452/0000280_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/452/0000192_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/320/frame9249_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/320/frame10822_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/320/frame2529_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/320/frame2015_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/320/frame11095_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/320/frame7479_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/320/frame17968_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/65/872878_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/65/524537_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/65/674886_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/65/458896_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/65/995255_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/102/064400_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/102/207103_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/102/731920_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/102/724325_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/102/515924_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/102/153272_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/102/922243_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/102/356154_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/102/680450_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/102/921951_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/102/790605_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/176/021088_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/176/017628_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/176/006475_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/176/026118_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/176/005755_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/176/020386_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/140/753454_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/140/843900_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/140/489187_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/140/443515_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/594461_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/021155_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/292646_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/738218_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/930866_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/810374_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/226722_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/563125_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/361065_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/804403_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/192249_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/192933_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/001325_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/593407_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/6/192470_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/247/frame3599_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/563/frame16785_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/563/frame7694_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/563/frame15253_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/563/frame4724_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/41/023393_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/41/020598_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/41/019363_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/41/020123_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/41/012763_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/41/006600_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/41/022359_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/41/012163_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/41/006300_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/2/593144_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/2/259377_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/141/017080_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/141/012668_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/141/023493_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/141/021693_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/141/010802_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/141/017689_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/522/frame0284_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/508/0002078_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/508/0003384_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/508/0001657_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/380/frame7672_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/380/frame21012_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/380/frame19935_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/380/frame21431_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/143/722198_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/211/frame3288_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/312/frame72406_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/312/frame72865_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/312/frame2227_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/312/frame75707_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/312/frame75598_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/312/frame74072_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/312/frame78182_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/312/frame71565_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/175/733676_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/175/266964_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/175/974291_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/441/frame6539_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/441/frame8714_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/441/frame5014_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/224/frame3157_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/166/638763_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/166/630773_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/166/627123_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/519/frame20626_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/383/frame20544_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/383/frame16780_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/383/frame15880_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/383/frame10971_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/383/frame20980_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/60/000216_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/226372_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/949698_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/427145_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/937777_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/441412_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/741628_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/402482_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/660653_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/891709_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/060156_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/381722_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/599123_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/545719_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/697321_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/165227_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/486389_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/952651_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/968610_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/579530_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/086568_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/887807_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/857646_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/401117_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/900548_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/045182_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/292033_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/965922_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/63/020075_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/462/frame2329_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/541/0000654_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/541/0002392_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/327/frame1249_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/482/frame3637_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/139/017846_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/139/007179_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/139/011161_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/5/007079_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/5/007919_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/5/021987_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/5/007844_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/5/002054_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/5/022101_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/5/009779_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/5/004906_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/5/017698_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/5/017473_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/544/0011001_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/544/0004070_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/544/0000444_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/544/0011310_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/544/0010050_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/544/0003865_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/544/0005977_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/544/0010753_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/544/0004856_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/532/0000002_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/532/0022486_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/532/0001216_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/532/0018898_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/532/0021984_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/532/0016013_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/532/0002124_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/532/0027229_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/532/0015588_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/532/0018613_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/468/frame4209_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/442/0004813_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/442/0000792_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/442/0005501_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/442/0003259_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/76/854592_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/76/236735_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/76/438410_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/7/107934_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/7/140819_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/7/529503_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/7/662556_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/28/026787_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/28/010201_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/28/021987_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/28/010441_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/28/024087_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/28/010471_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/28/023487_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/110/017628_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/110/014678_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/110/026078_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/110/007178_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/110/015309_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/110/002222_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/110/026123_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/110/007246_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/110/007073_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/403/0006531_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/403/0005358_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/403/0010639_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/403/0005852_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/403/0013321_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/403/0010815_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/171/934211_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/171/601555_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/171/607087_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/476/frame88492_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/476/frame33274_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/476/frame34374_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/476/frame85874_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/16/842971_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/16/925743_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/16/848588_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/295/frame22543_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/295/frame1119_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/295/frame22324_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/413/frame0399_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/40/577720_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/40/901121_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/40/117671_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/40/245825_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/75/050841_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/75/455758_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/75/431385_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/75/015933_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/75/218217_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/20/001984_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/20/002071_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/20/009997_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/20/010409_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/20/012541_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/20/002784_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/20/024533_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/20/012436_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/20/003784_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/20/017489_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/20/022885_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/322/frame2969_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/322/frame0809_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/213/frame55703_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/213/frame32794_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/213/frame24203_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/213/frame42771_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/213/frame45453_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/213/frame39635_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/213/frame57499_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/213/frame41817_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/213/frame3809_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/213/frame50385_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/69/016340_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/69/014221_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/57/081037_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/57/498375_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/57/762426_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/57/500089_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/57/095450_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/57/123572_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame19658_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame18930_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame1434_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame5867_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame1759_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame17862_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame16271_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame5267_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame4442_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame8842_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame18044_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/512/frame1934_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/302/frame14638_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/302/frame12944_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/302/frame14670_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/302/frame4516_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/302/frame14615_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/302/frame14973_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/302/frame4672_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/118/945946_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/118/023504_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/357/frame14140_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/357/frame28621_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/357/frame11266_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/357/frame27062_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/357/frame32781_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/357/frame3838_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/357/frame27179_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/357/frame32462_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/357/frame5939_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/32/328901_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/32/721205_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/32/194242_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/32/652073_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/32/512106_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/32/359279_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/32/523103_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/454/frame0005_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/203/frame0945_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/203/frame1975_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame42802_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame5033_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame11179_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame70993_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame3363_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame67884_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame12348_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame64239_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame17466_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame41720_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame47202_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame20484_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame41502_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame13397_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame44357_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame16893_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame19139_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame59057_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame70766_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/460/frame56020_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/506/frame5324_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/506/frame3974_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/471/0003290_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/30/076428_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/30/364999_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/30/067149_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/30/844914_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/30/746375_image.jpg',\n",
              " 'drive/My Drive/idd-lite/idd20k_lite/leftImg8bit/train/1/340676_image.jpg',\n",
              " ...]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJXKKV05nr5i"
      },
      "source": [
        "## Data Preparation "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bp5XLcYnr5k"
      },
      "source": [
        "# Image size that we are going to use\n",
        "(HEIGHT,WIDTH) = (128,128)\n",
        "# Our images are RGB (3 channels)\n",
        "N_CHANNELS = 3\n",
        "# Scene Parsing has 7 classes (0-6) + `not labeled`\n",
        "N_CLASSES = 8"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8_AtJ8Bnr5m",
        "outputId": "f35bc24b-385e-479c-ded6-ed2470c7cb1b"
      },
      "source": [
        "# Reference -> https://docs.python.org/2/library/glob.html\n",
        "# The glob module finds all the pathnames matching a specified pattern according to the rules used by the Unix shell, \n",
        "# although results are returned in arbitrary order. \n",
        "\n",
        "TRAINSET_SIZE = len(glob(img_train+'*/*_image.jpg'))\n",
        "print(f\"The Training Dataset contains {TRAINSET_SIZE} images.\")\n",
        "\n",
        "VALSET_SIZE = len(glob(img_val+'*/*_image.jpg'))\n",
        "print(f\"The Validation Dataset contains {VALSET_SIZE} images.\")"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Training Dataset contains 1403 images.\n",
            "The Validation Dataset contains 204 images.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ksntANjnr5p"
      },
      "source": [
        "def parse_image(img_path):\n",
        "    \"\"\"\n",
        "    Load an image and its annotation (mask) and returning a dictionary.\n",
        "    \"\"\"\n",
        "    # Reading the image\n",
        "    image = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    # For one Image path:\n",
        "    # .../idd20k_lite/leftImg8bit/train/024541_image.jpg\n",
        "    # Its corresponding annotation path is:\n",
        "    # .../idd20k_lite/gtFine/train/024541_label.png\n",
        "    mask_path = tf.strings.regex_replace(img_path, \"leftImg8bit\", \"gtFine\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"_image.jpg\", \"_label.png\")\n",
        "    # Reading the annotation file corresponding the image file\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    # In scene parsing, \"not labeled\" = 255\n",
        "    # But it will mess with our N_CLASS = 7\n",
        "    # Since 255 means the 255th class\n",
        "    # Which doesn't exist\n",
        "    mask = tf.where(mask==255, np.dtype('uint8').type(7), mask)\n",
        "    # Note that we have to convert the new value (7)\n",
        "    # With the same dtype than the tensor itself\n",
        "    return {'image': image, 'segmentation_mask': mask}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sIxF4YUanr5s"
      },
      "source": [
        "# Reference -> https://www.tensorflow.org/api_docs/python/tf/data/Dataset#list_files\n",
        "# tf.data.Dataset.list_files returns a dataset of all files matching one or more glob patterns.\n",
        "\n",
        "train_dataset = tf.data.Dataset.list_files(img_train+'*/*_image.jpg', seed=SEED)\n",
        "train_dataset = train_dataset.map(parse_image)\n",
        "\n",
        "val_dataset = tf.data.Dataset.list_files(img_val+'*/*_image.jpg', seed=SEED)\n",
        "val_dataset =val_dataset.map(parse_image)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRpudDSOnr5v"
      },
      "source": [
        "# Reference -> https://www.tensorflow.org/api_docs/python/tf/cast\n",
        "# Returns a Tensor same shape as given tensor and same type as dtype that is mentioned.\n",
        "\n",
        "def normalize(input_image, input_mask):\n",
        "    \"\"\"\n",
        "    Rescale the pixel values of the images between 0 and 1 compared to [0,255] originally.\n",
        "    \"\"\"\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    return input_image, input_mask"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kZ1AAuYlnr5x"
      },
      "source": [
        "# Reference -> https://www.tensorflow.org/api_docs/python/tf/image/resize\n",
        "# Resize images to the size specified\n",
        "\n",
        "def load_image_train(datapoint):\n",
        "    \"\"\"\n",
        "    Normalize and resize a train image and its annotation.\n",
        "    Apply random transformations to an input dictionary containing a train image and its annotation.\n",
        "    \"\"\"\n",
        "    input_image = tf.image.resize(datapoint['image'], (HEIGHT,WIDTH))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (HEIGHT,WIDTH))\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_image_test(datapoint):\n",
        "    \"\"\"\n",
        "    Normalize and resize a test image and its annotation.\n",
        "    Since this is for the test set, we don't need to apply any data augmentation technique.\n",
        "    \"\"\"\n",
        "    input_image = tf.image.resize(datapoint['image'], (HEIGHT,WIDTH))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (HEIGHT,WIDTH))\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZQF444Qcnr5z"
      },
      "source": [
        "BATCH_SIZE = 16\n",
        "BUFFER_SIZE = 1500\n",
        "dataset = {\"train\": train_dataset, \"val\": val_dataset}"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3n8IUocnr52",
        "outputId": "5709dda6-4969-4761-d407-7b8d42d0533f"
      },
      "source": [
        "# Reference -> https://www.tensorflow.org/api_docs/python/tf/data/Dataset\n",
        "\n",
        "# Preparing the Train dataset by applying dataset transformations\n",
        "dataset['train'] = dataset['train'].map(load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
        "dataset['train'] = dataset['train'].repeat()\n",
        "dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
        "dataset['train'] = dataset['train'].prefetch(buffer_size=AUTOTUNE)\n",
        "print(dataset['train'])\n",
        "\n",
        "# Preparing the Validation Dataset\n",
        "dataset['val'] = dataset['val'].map(load_image_test)\n",
        "dataset['val'] = dataset['val'].repeat()\n",
        "dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
        "dataset['val'] = dataset['val'].prefetch(buffer_size=AUTOTUNE)\n",
        "print(dataset['val'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: ((None, 128, 128, 3), (None, 128, 128, 1)), types: (tf.float32, tf.float32)>\n",
            "<PrefetchDataset shapes: ((None, 128, 128, 3), (None, 128, 128, 1)), types: (tf.float32, tf.float32)>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sg7Md8kmWJ34"
      },
      "source": [
        "# PSPNet from Scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDEAJfhTIPuB"
      },
      "source": [
        "# A class to get the basic convolution block \n",
        "# convolution_layer -> batch_normalization -> activation\n",
        "class BasicConvolutionBlock(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, filter_size, kernel_size, dilation_rate, alpha, block_number, initializer='he_normal'):\n",
        "        super(BasicConvolutionBlock, self).__init__()\n",
        "        self.block_number = block_number\n",
        "        self.convolution_layer = Convolution2D(filter_size, kernel_size =  kernel_size, \n",
        "                                               dilation_rate = dilation_rate, padding = 'same',\n",
        "                                               kernel_initializer = initializer)\n",
        "        self.batch_normalization = BatchNormalization()\n",
        "        self.activation = LeakyReLU(alpha = alpha)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        conv_output = self.convolution_layer(inputs)\n",
        "        norm_output = self.batch_normalization(conv_output)\n",
        "        if(self.block_number >= 3):\n",
        "            return norm_output\n",
        "        activation_output = self.activation(norm_output)  \n",
        "        return activation_output"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua2CSUuvIPuD"
      },
      "source": [
        "# A Building Block of Residual Network\n",
        "class ConvolutionBlock(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, filters, initializer='he_normal'):     \n",
        "        super(ConvolutionBlock, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.basic_convolution_1 = BasicConvolutionBlock(self.filters[0], (1,1), (1,1), 0.2, 1)\n",
        "        self.basic_convolution_2 = BasicConvolutionBlock(self.filters[1], (3,3), (2,2), 0.2, 2)\n",
        "        self.basic_convolution_3 = BasicConvolutionBlock(self.filters[2], (1,1), (1,1), None, 3)\n",
        "        self.skip_convolution = BasicConvolutionBlock(self.filters[2], (3,3), (1,1), None, 4)\n",
        "        # Last Block\n",
        "        self.add_layer = Add()\n",
        "        self.relu_activation = ReLU()\n",
        "     \n",
        "    def call(self, inputs):\n",
        "        skip_input = inputs\n",
        "        output_conv_1 = self.basic_convolution_1(inputs)\n",
        "        output_conv_2 = self.basic_convolution_2(output_conv_1)\n",
        "        output_conv_3 = self.basic_convolution_3(output_conv_2)\n",
        "        output_skip_conv = self.skip_convolution(skip_input)\n",
        "        # Last Block\n",
        "        add_output = self.add_layer([output_conv_3,output_skip_conv])\n",
        "        output = self.relu_activation(add_output)\n",
        "        return output"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2rtNpM3_IPuE"
      },
      "source": [
        "# Encoder block for PSPNet Net\n",
        "class EncoderBlock(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, filters):\n",
        "        super(EncoderBlock, self).__init__()\n",
        "        self.filters = filters\n",
        "        self.convolution_block_1 = ConvolutionBlock(self.filters[0])\n",
        "        self.convolution_block_2 = ConvolutionBlock(self.filters[1])\n",
        "        self.convolution_block_3 = ConvolutionBlock(self.filters[2])\n",
        "        self.convolution_block_4 = ConvolutionBlock(self.filters[3])\n",
        "        \n",
        "    def call(self, inputs):     \n",
        "        output_block_1 = self.convolution_block_1(inputs)\n",
        "        output_block_2 = self.convolution_block_2(output_block_1)\n",
        "        output_block_3 = self.convolution_block_3(output_block_2) \n",
        "        output_block_4 = self.convolution_block_4(output_block_3)\n",
        "        return output_block_4"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtEBVUAFIPuG"
      },
      "source": [
        "# This class returns the pyramid feature map for Pyramid Pooling module\n",
        "# Pooling -> Convolution -> UpSampling\n",
        "class PyramidFeatureMap(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, block, filter_size, unsampling_size, pool_size, interpolation='bilinear'):\n",
        "        super(PyramidFeatureMap, self).__init__()\n",
        "        self.block = block\n",
        "        self.convolution_layer = Convolution2D(filter_size, kernel_size = (1,1))\n",
        "        self.upsampling_layer = UpSampling2D(unsampling_size, interpolation = interpolation)\n",
        "        self.average_pooling = AveragePooling2D(pool_size)\n",
        "        self.global_average_pooling = GlobalAveragePooling2D()\n",
        "        \n",
        "    def call(self,inputs):\n",
        "        if(self.block=='red'):\n",
        "            pool_output = self.global_average_pooling(inputs)\n",
        "            pool_output = Reshape((1,1,512))(pool_output)\n",
        "        else:\n",
        "            pool_output = self.average_pooling(inputs)\n",
        "        conv_output = self.convolution_layer(pool_output)\n",
        "        upsampling_output = self.upsampling_layer(conv_output)\n",
        "        return upsampling_output        "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gp5p-eeQIPuJ"
      },
      "source": [
        "# This class builds the Pyramid Pooling Module\n",
        "# It builds the 4 feature maps and then concatenates all of them with the input\n",
        "class PyramidPoolingModule(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(PyramidPoolingModule, self).__init__()\n",
        "        self.block_red = PyramidFeatureMap('red', 64, (128,128), (1,1))\n",
        "        self.block_yellow = PyramidFeatureMap('yellow', 64, 2, (2,2))\n",
        "        self.block_blue = PyramidFeatureMap('blue', 64, 4, (4,4))\n",
        "        self.block_green = PyramidFeatureMap('green', 64, 8, (8,8))\n",
        "        \n",
        "    def call(self,inputs):\n",
        "        red_output = self.block_red(inputs)\n",
        "        yellow_output = self.block_yellow(inputs)\n",
        "        blue_output = self.block_blue(inputs)\n",
        "        green_output = self.block_green(inputs)\n",
        "        merged = concatenate([inputs, red_output, yellow_output, blue_output, green_output])\n",
        "        return merged  "
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKlKJ5SVIPuL"
      },
      "source": [
        "# This block is for the last stage\n",
        "# It gets the output of Pyramid Pooling Module and then performs convolution operation\n",
        "# Pyramid Pooling -> Convolution -> Batch Normalization -> Softmax activation\n",
        "class DecoderBlock(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.pyramid_pooling_module = PyramidPoolingModule()\n",
        "        self.convolution_layer = Convolution2D(num_classes, kernel_size = (3,3), padding = 'same')\n",
        "        self.batch_norm_layer = BatchNormalization()\n",
        "        self.activation = Activation('softmax')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        merged = self.pyramid_pooling_module(inputs)\n",
        "        conv_output = self.convolution_layer(merged)\n",
        "        norm_output = self.batch_norm_layer(conv_output)\n",
        "        output = self.activation(norm_output)\n",
        "        return output"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SKIp8d7IPuN"
      },
      "source": [
        "#This final class for the Model\n",
        "class PSPNetModel(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super(PSPNetModel, self).__init__()\n",
        "        self.encoder = EncoderBlock([[32,32,64],[64,64,128],[128,128,256],[256,256,512]])\n",
        "        self.decoder = DecoderBlock(num_classes)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        encoder_output = self.encoder(inputs)\n",
        "        final_output = self.decoder(encoder_output)\n",
        "        return final_output"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CTzjSCt9Fgg"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "# SegmentationModel object\n",
        "model = PSPNetModel(N_CLASSES)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "byhYZrak9pOf"
      },
      "source": [
        "# Defining a loss object and an optimizer\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=model)\n",
        "manager = tf.train.CheckpointManager(ckpt, 'tf_ckpts/', max_to_keep=3)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EpC2stF9nIg"
      },
      "source": [
        "# Define the metrics\n",
        "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpLXhPka9jc0"
      },
      "source": [
        "# Reference -> https://github.com/junhoning/machine_learning_tutorial/blob/b20b8a10438ec3e62f08f920744cc8ea854cde91/Visualization%20%26%20TensorBoard/%5BTensorBoard%5D%20Semantic%20Segmentation.ipynb\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, optimizer, x_train, y_train):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(x_train, training=True)\n",
        "        loss = loss_object(y_train, predictions)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(y_train, predictions)\n",
        "    \n",
        "def train_and_checkpoint(model, manager, dataset, epoch):\n",
        "    ckpt.restore(manager.latest_checkpoint)\n",
        "    if manager.latest_checkpoint:\n",
        "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "    else:\n",
        "        print(\"Initializing from scratch.\")\n",
        "    for (x_train, y_train) in dataset['train'].take(math.ceil(1403/8)):\n",
        "        train_step(model, optimizer, x_train, y_train)\n",
        "    ckpt.step.assign_add(1)\n",
        "    save_path = manager.save()\n",
        "    print(\"Saved checkpoint for epoch {}: {}\".format(epoch, save_path))\n",
        "    \n",
        "@tf.function\n",
        "def test_step(model, x_test, y_test):\n",
        "    predictions = model(x_test)\n",
        "    loss = loss_object(y_test, predictions)\n",
        "    test_loss(loss)\n",
        "    test_accuracy(y_test, predictions)\n",
        "    return predictions"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMnqVwF29gZz"
      },
      "source": [
        "train_log_dir = 'logs/gradient_tape/train'\n",
        "test_log_dir = 'logs/gradient_tape/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 249
        },
        "id": "Cp8uAicC9ct-",
        "scrolled": true,
        "outputId": "59aed145-a0da-4f72-c855-5440680e0722"
      },
      "source": [
        "# This variable will help to save the best model if its performance increases after an epoch   \n",
        "highest_accuracy = 0\n",
        "\n",
        "# Training the model for 40 epochs\n",
        "for epoch in range(50):\n",
        "\n",
        "    print(\"Epoch \",epoch+1)\n",
        "    \n",
        "    # Getting the current time before starting the training\n",
        "    # This will help to keep track of how much time an epoch took\n",
        "    start = time.time()\n",
        "    \n",
        "    train_and_checkpoint(model, manager, dataset, epoch+1)\n",
        "    \n",
        "    # Saving the train loss and train accuracy metric for TensorBoard visualization\n",
        "    with train_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', train_loss.result(), step=ckpt.step.numpy())\n",
        "        tf.summary.scalar('accuracy', train_accuracy.result(), step=ckpt.step.numpy())\n",
        "    \n",
        "    # Validation phase\n",
        "    for (x_test, y_test) in dataset['val'].take(math.ceil(204/8)):\n",
        "        pred = test_step(model, x_test, y_test)\n",
        "    \n",
        "    # Saving the validation loss and validation accuracy metric for Tensorboard visualization\n",
        "    with test_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', test_loss.result(), step=ckpt.step.numpy())\n",
        "        tf.summary.scalar('accuracy', test_accuracy.result(), step=ckpt.step.numpy())\n",
        "    \n",
        "    # Calculating the time it took for the entire epoch to run\n",
        "    print(\"Time taken \",time.time()-start)\n",
        "    \n",
        "    # Printing the metrics for the epoch\n",
        "    template = 'Epoch {}, Loss: {:.3f}, Accuracy: {:.3f}, Val Loss: {:.3f}, Val Accuracy: {:.3f}'\n",
        "    print (template.format(epoch+1,\n",
        "                            train_loss.result(), \n",
        "                            train_accuracy.result()*100,\n",
        "                            test_loss.result(), \n",
        "                            test_accuracy.result()*100))\n",
        "    \n",
        "    # If accuracy has increased in this epoch, updating the highest accuracy and saving the model\n",
        "    if(test_accuracy.result().numpy()*100>highest_accuracy):\n",
        "        print(\"Validation accuracy increased from {:.3f} to {:.3f}. Saving model weights.\".format(highest_accuracy,test_accuracy.result().numpy()*100))\n",
        "        highest_accuracy = test_accuracy.result().numpy()*100\n",
        "        model.save_weights('pspnet_weights-epoch-{}.hdf5'.format(epoch+1))\n",
        "\n",
        "    print('_'*80)\n",
        "\n",
        "    # Reset metrics after every epoch\n",
        "    train_loss.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-8fcb754f6759>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# Getting the current time before starting the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# This will help to keep track of how much time an epoch took\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mtrain_and_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmanager\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'time' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiC5OCjWWJ4C",
        "outputId": "8f06d75d-00b8-4a63-f067-733dedf4208b"
      },
      "source": [
        "from IPython.core.display import Image, display\n",
        "display(Image('From scratch.png'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "From scratch.png",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "E5w80STlIPu-",
        "outputId": "5797034a-cc97-490a-8e13-05b542cdd7ce"
      },
      "source": [
        "# Loading the weights of the best model\n",
        "model.load_weights('pspnet_weights-epoch-42.hdf5')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-0c4cffb191e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Loading the weights of the best model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pspnet_weights-epoch-42.hdf5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mload_weights\u001b[0;34m(self, filepath, by_name, skip_mismatch, options)\u001b[0m\n\u001b[1;32m   2225\u001b[0m           'first, then load the weights.')\n\u001b[1;32m   2226\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2227\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mh5py\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2228\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'layer_names'\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m'model_weights'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2229\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_weights'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, **kwds)\u001b[0m\n\u001b[1;32m    406\u001b[0m                 fid = make_fid(name, mode, userblock_size,\n\u001b[1;32m    407\u001b[0m                                \u001b[0mfapl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfcpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmake_fcpl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrack_order\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 408\u001b[0;31m                                swmr=swmr)\n\u001b[0m\u001b[1;32m    409\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    410\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlibver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/h5py/_hl/files.py\u001b[0m in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mswmr\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mswmr_support\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m|=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_SWMR_READ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 173\u001b[0;31m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    174\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'r+'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh5f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mACC_RDWR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfapl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfapl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mh5py/h5f.pyx\u001b[0m in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: Unable to open file (unable to open file: name = 'pspnet_weights-epoch-42.hdf5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcxMwQOMxW75"
      },
      "source": [
        "def predict(model,image_path):\n",
        "    \"\"\"\n",
        "    This function will take the model which is going to be used to predict the image and the image path of \n",
        "    the input image as inputs and predict the mask\n",
        "    It returns the true mask and predicted mask\n",
        "    \"\"\"\n",
        "    # Getting the datapoint\n",
        "    # This function will load the image and its annotation (mask) and return a dictionary.\n",
        "    datapoint = parse_image(image_path)\n",
        "    # Normalizing the resizing the datapoint\n",
        "    input_image,image_mask = load_image_test(datapoint)\n",
        "    # As the model takes input with 4 dimensions (batch_size, rows, columns, channels),\n",
        "    # and the shape of the input image is (rows, columns, channels)\n",
        "    # we will expand the first dimension so we will get the shape as  (1, rows, columns, channels)\n",
        "    img = tf.expand_dims(input_image, 0)\n",
        "    # Predicting the image by passing it to the model\n",
        "    prediction = model(img)\n",
        "    # The model will predict 8 outputs for each pixel\n",
        "    # We have to get the maximum value out of it\n",
        "    prediction = tf.argmax(prediction, axis=-1)\n",
        "    prediction = tf.squeeze(prediction, axis = 0)\n",
        "    pred_mask = tf.expand_dims(prediction, axis=-1)\n",
        "    # Displaying the input image, true mask, predicted mask\n",
        "    #display_sample([input_image, image_mask, pred_mask])\n",
        "    return image_mask, pred_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdb_IrorxkXN"
      },
      "source": [
        "# Reference -> https://github.com/saisandeepNSS/IDD_SemanticSegmentation\n",
        "\n",
        "def IoU(y_i,y_pred):\n",
        "    # This function calculates the mean Intersection over Union\n",
        "    # Mean IoU = TP/(FN + TP + FP)\n",
        "    # This list will save the IoU of all the classes\n",
        "    IoUs = []\n",
        "    # Defining the number of classes which the model has predicted\n",
        "    n_classes = 8\n",
        "    for c in range(n_classes):\n",
        "        # Calculating the True Positives\n",
        "        TP = np.sum((y_i == c)&(y_pred==c))\n",
        "        # Calculating the False Positives\n",
        "        FP = np.sum((y_i != c)&(y_pred==c))\n",
        "        # Calculating the False Negatives\n",
        "        FN = np.sum((y_i == c)&(y_pred!= c))\n",
        "        # Calculating the IoU for the particular class\n",
        "        IoU = TP/float(TP + FP + FN)\n",
        "        # Printing the outputs\n",
        "        # Uncomment the print statement below when you want to analyze the results for each class\n",
        "        #print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\".format(c,TP,FP,FN,IoU))\n",
        "        # Appending the IoU to the list as it mean needs to be calculated later\n",
        "        if(math.isnan(IoU)):\n",
        "            IoUs.append(0)\n",
        "            continue\n",
        "        IoUs.append(IoU)\n",
        "    # Calculating the mean\n",
        "    mIoU = np.mean(IoUs)\n",
        "    #print(\"_________________\")\n",
        "    #print(\"Mean IoU: {:4.3f}\".format(mIoU))\n",
        "    return mIoU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K0m_pvx0FiD"
      },
      "source": [
        "### Validation mIoU for PSPNet from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6ERQK1g_RAk"
      },
      "source": [
        "img_val = dataset_path + 'leftImg8bit/val/'\n",
        "val_paths = glob(img_val+'*/*_image.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugUHIIqfz7du"
      },
      "source": [
        "mIoU = []\n",
        "for path in val_paths:\n",
        "    true_mask, pred_mask = predict(model,path)\n",
        "    mIoU.append(IoU(true_mask, pred_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k43_RFJgz9Af",
        "outputId": "309f9d6a-23ba-4322-8c5b-190ba03bd01c"
      },
      "source": [
        "print(\"Validation mIoU = \",sum(mIoU)/len(mIoU))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation mIoU =  0.44050398081737924\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlp6L3R9WJ4F"
      },
      "source": [
        "# PSPNet with a pretrained Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nAnfsJb7m_ka"
      },
      "source": [
        "from tensorflow.keras.applications.resnet50 import ResNet50"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-EUGYncWJ4F"
      },
      "source": [
        "# This class returns the pyramid feature map for Pyramid Pooling module\n",
        "# Pooling -> Convolution -> UpSampling\n",
        "class PyramidFeatureMap(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, block, filter_size, unsampling_size, pool_size, interpolation='bilinear'):\n",
        "        super(PyramidFeatureMap, self).__init__()\n",
        "        self.block = block\n",
        "        self.convolution_layer = Convolution2D(filter_size, kernel_size = (1,1))\n",
        "        self.upsampling_layer = UpSampling2D(unsampling_size, interpolation = interpolation)\n",
        "        self.average_pooling = AveragePooling2D(pool_size)\n",
        "        self.global_average_pooling = GlobalAveragePooling2D()\n",
        "        \n",
        "    def call(self,inputs):\n",
        "        if(self.block=='red'):\n",
        "            pool_output = self.global_average_pooling(inputs)\n",
        "            pool_output = Reshape((1,1,2048))(pool_output)\n",
        "        else:\n",
        "            pool_output = self.average_pooling(inputs)\n",
        "        conv_output = self.convolution_layer(pool_output)\n",
        "        upsampling_output = self.upsampling_layer(conv_output)\n",
        "        return upsampling_output        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHGTO7IeWJ4G"
      },
      "source": [
        "# This class builds the Pyramid Pooling Module\n",
        "# It builds the 4 feature maps and then concatenates all of them with the input\n",
        "class PyramidPoolingModule(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self):\n",
        "        super(PyramidPoolingModule, self).__init__()\n",
        "        self.block_red = PyramidFeatureMap('red', 64, 8, (1,1))\n",
        "        self.block_yellow = PyramidFeatureMap('yellow', 64, 2, (2,2))\n",
        "        self.block_blue = PyramidFeatureMap('blue', 64, 4, (3,3))\n",
        "        self.block_green = PyramidFeatureMap('green', 64, 8, (6,6))\n",
        "        \n",
        "    def call(self,inputs):\n",
        "        red_output = self.block_red(inputs)\n",
        "        yellow_output = self.block_yellow(inputs)\n",
        "        blue_output = self.block_blue(inputs)\n",
        "        green_output = self.block_green(inputs)\n",
        "        merged = concatenate([inputs, red_output, yellow_output, blue_output, green_output])\n",
        "        return merged  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ieKni5U_WJ4G"
      },
      "source": [
        "# This block is for the last stage\n",
        "# It gets the output of Pyramid Pooling Module and then performs convolution operation\n",
        "# Pyramid Pooling -> Convolution -> Batch Normalization -> Softmax activation\n",
        "class DecoderBlock(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super(DecoderBlock, self).__init__()\n",
        "        self.pyramid_pooling_module = PyramidPoolingModule()\n",
        "        self.convolution_layer = Convolution2D(num_classes, kernel_size = (3,3), padding = 'same')\n",
        "        self.batch_norm_layer = BatchNormalization()\n",
        "        self.activation = Activation('softmax')\n",
        "    \n",
        "    def call(self, inputs):\n",
        "        merged = self.pyramid_pooling_module(inputs)\n",
        "        conv_output = self.convolution_layer(merged)\n",
        "        norm_output = self.batch_norm_layer(conv_output)\n",
        "        output = self.activation(norm_output)\n",
        "        return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqQRLa-lWJ4G"
      },
      "source": [
        "#This final class for the Model\n",
        "class PSPNetModel(tf.keras.Model):\n",
        "    \n",
        "    def __init__(self, num_classes):\n",
        "        super(PSPNetModel, self).__init__()\n",
        "        self.resnet = ResNet50(weights='imagenet', include_top = False, input_shape = (128,128,3))\n",
        "        for layer in self.resnet.layers:\n",
        "            layer.trainable = False\n",
        "        self.upsampling_encoder = UpSampling2D(size=(2,2), interpolation='bilinear')\n",
        "        self.upsampling = UpSampling2D(size=(16,16), interpolation='bilinear')\n",
        "        self.decoder = DecoderBlock(num_classes)\n",
        "        \n",
        "    def call(self, inputs):\n",
        "        encoder_output = self.resnet(inputs)\n",
        "        encoder_output = self.upsampling_encoder(encoder_output)\n",
        "        decoder_output = self.decoder(encoder_output)\n",
        "        final_output = self.upsampling(decoder_output)\n",
        "        return final_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QWlk6EfTWJ4H",
        "outputId": "66030c9f-3d99-43c5-806f-c0bef6557643"
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "# SegmentationModel object\n",
        "model = PSPNetModel(N_CLASSES)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "94773248/94765736 [==============================] - 4s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_eUcqaZWJ4H"
      },
      "source": [
        "# Defining a loss object and an optimizer\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=model)\n",
        "manager = tf.train.CheckpointManager(ckpt, 'tf_ckpts/', max_to_keep=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "53oBR-iHWJ4I"
      },
      "source": [
        "# Define the metrics\n",
        "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGQNM8pxWJ4I"
      },
      "source": [
        "# Reference -> https://github.com/junhoning/machine_learning_tutorial/blob/b20b8a10438ec3e62f08f920744cc8ea854cde91/Visualization%20%26%20TensorBoard/%5BTensorBoard%5D%20Semantic%20Segmentation.ipynb\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, optimizer, x_train, y_train):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(x_train, training=True)\n",
        "        loss = loss_object(y_train, predictions)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(y_train, predictions)\n",
        "    \n",
        "def train_and_checkpoint(model, manager, dataset, epoch):\n",
        "    '''\n",
        "    ckpt.restore(manager.latest_checkpoint)\n",
        "    if manager.latest_checkpoint:\n",
        "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "    else:\n",
        "        print(\"Initializing from scratch.\")'''\n",
        "    for (x_train, y_train) in dataset['train'].take(math.ceil(1403/16)):\n",
        "        train_step(model, optimizer, x_train, y_train)\n",
        "    ckpt.step.assign_add(1)\n",
        "    save_path = manager.save()\n",
        "    print(\"Saved checkpoint for epoch {}: {}\".format(epoch, save_path))\n",
        "    \n",
        "@tf.function\n",
        "def test_step(model, x_test, y_test):\n",
        "    predictions = model(x_test)\n",
        "    loss = loss_object(y_test, predictions)\n",
        "    test_loss(loss)\n",
        "    test_accuracy(y_test, predictions)\n",
        "    return predictions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DlvAtWKUWJ4I"
      },
      "source": [
        "train_log_dir = 'logs/gradient_tape/train'\n",
        "test_log_dir = 'logs/gradient_tape/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mfrCjZMLWJ4I",
        "scrolled": true,
        "outputId": "6b8f0860-060a-4241-cae3-5c435bce0c00"
      },
      "source": [
        "# This variable will help to save the best model if its performance increases after an epoch   \n",
        "highest_accuracy = 0\n",
        "\n",
        "# Training the model for 50 epochs\n",
        "for epoch in range(50):\n",
        "\n",
        "    print(\"Epoch \",epoch+1)\n",
        "    \n",
        "    # Getting the current time before starting the training\n",
        "    # This will help to keep track of how much time an epoch took\n",
        "    start = time.time()\n",
        "    \n",
        "    train_and_checkpoint(model, manager, dataset, epoch+1)\n",
        "    \n",
        "    # Saving the train loss and train accuracy metric for TensorBoard visualization\n",
        "    with train_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', train_loss.result(), step=ckpt.step.numpy())\n",
        "        tf.summary.scalar('accuracy', train_accuracy.result(), step=ckpt.step.numpy())\n",
        "    \n",
        "    # Validation phase\n",
        "    for (x_test, y_test) in dataset['val'].take(math.ceil(204/16)):\n",
        "        pred = test_step(model, x_test, y_test)\n",
        "    \n",
        "    # Saving the validation loss and validation accuracy metric for Tensorboard visualization\n",
        "    with test_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', test_loss.result(), step=ckpt.step.numpy())\n",
        "        tf.summary.scalar('accuracy', test_accuracy.result(), step=ckpt.step.numpy())\n",
        "    \n",
        "    # Calculating the time it took for the entire epoch to run\n",
        "    print(\"Time taken \",time.time()-start)\n",
        "    \n",
        "    # Printing the metrics for the epoch\n",
        "    template = 'Epoch {}, Loss: {:.3f}, Accuracy: {:.3f}, Val Loss: {:.3f}, Val Accuracy: {:.3f}'\n",
        "    print (template.format(epoch+1,\n",
        "                            train_loss.result(), \n",
        "                            train_accuracy.result()*100,\n",
        "                            test_loss.result(), \n",
        "                            test_accuracy.result()*100))\n",
        "    \n",
        "    # If accuracy has increased in this epoch, updating the highest accuracy and saving the model\n",
        "    if(test_accuracy.result().numpy()*100>highest_accuracy):\n",
        "        print(\"Validation accuracy increased from {:.3f} to {:.3f}. Saving model weights.\".format(highest_accuracy,test_accuracy.result().numpy()*100))\n",
        "        highest_accuracy = test_accuracy.result().numpy()*100\n",
        "        model.save_weights('pspnet_weights-epoch-{}.hdf5'.format(epoch+1))\n",
        "\n",
        "    print('_'*80)\n",
        "\n",
        "    # Reset metrics after every epoch\n",
        "    train_loss.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch  1\n",
            "Saved checkpoint for epoch 1: tf_ckpts/ckpt-1\n",
            "Time taken  14.84341549873352\n",
            "Epoch 1, Loss: 1.410, Accuracy: 54.055, Val Loss: 1.793, Val Accuracy: 41.005\n",
            "Validation accuracy increased from 0.000 to 41.005. Saving model weights.\n",
            "________________________________________________________________________________\n",
            "Epoch  2\n",
            "Saved checkpoint for epoch 2: tf_ckpts/ckpt-2\n",
            "Time taken  10.578563690185547\n",
            "Epoch 2, Loss: 1.228, Accuracy: 61.762, Val Loss: 1.329, Val Accuracy: 60.176\n",
            "Validation accuracy increased from 41.005 to 60.176. Saving model weights.\n",
            "________________________________________________________________________________\n",
            "Epoch  3\n",
            "Saved checkpoint for epoch 3: tf_ckpts/ckpt-3\n",
            "Time taken  9.706828117370605\n",
            "Epoch 3, Loss: 1.138, Accuracy: 63.978, Val Loss: 1.268, Val Accuracy: 63.520\n",
            "Validation accuracy increased from 60.176 to 63.520. Saving model weights.\n",
            "________________________________________________________________________________\n",
            "Epoch  4\n",
            "Saved checkpoint for epoch 4: tf_ckpts/ckpt-4\n",
            "Time taken  9.750963926315308\n",
            "Epoch 4, Loss: 1.080, Accuracy: 65.174, Val Loss: 1.182, Val Accuracy: 62.395\n",
            "________________________________________________________________________________\n",
            "Epoch  5\n",
            "Saved checkpoint for epoch 5: tf_ckpts/ckpt-5\n",
            "Time taken  10.388520956039429\n",
            "Epoch 5, Loss: 1.037, Accuracy: 65.901, Val Loss: 1.042, Val Accuracy: 64.862\n",
            "Validation accuracy increased from 63.520 to 64.862. Saving model weights.\n",
            "________________________________________________________________________________\n",
            "Epoch  6\n",
            "Saved checkpoint for epoch 6: tf_ckpts/ckpt-6\n",
            "Time taken  9.610873937606812\n",
            "Epoch 6, Loss: 1.003, Accuracy: 66.365, Val Loss: 1.098, Val Accuracy: 63.108\n",
            "________________________________________________________________________________\n",
            "Epoch  7\n",
            "Saved checkpoint for epoch 7: tf_ckpts/ckpt-7\n",
            "Time taken  9.721731424331665\n",
            "Epoch 7, Loss: 0.974, Accuracy: 66.813, Val Loss: 1.007, Val Accuracy: 65.784\n",
            "Validation accuracy increased from 64.862 to 65.784. Saving model weights.\n",
            "________________________________________________________________________________\n",
            "Epoch  8\n",
            "Saved checkpoint for epoch 8: tf_ckpts/ckpt-8\n",
            "Time taken  9.600408554077148\n",
            "Epoch 8, Loss: 0.956, Accuracy: 66.840, Val Loss: 1.065, Val Accuracy: 61.826\n",
            "________________________________________________________________________________\n",
            "Epoch  9\n",
            "Saved checkpoint for epoch 9: tf_ckpts/ckpt-9\n",
            "Time taken  9.711277961730957\n",
            "Epoch 9, Loss: 0.940, Accuracy: 67.063, Val Loss: 1.014, Val Accuracy: 64.122\n",
            "________________________________________________________________________________\n",
            "Epoch  10\n",
            "Saved checkpoint for epoch 10: tf_ckpts/ckpt-10\n",
            "Time taken  9.620885372161865\n",
            "Epoch 10, Loss: 0.920, Accuracy: 67.537, Val Loss: 0.973, Val Accuracy: 65.363\n",
            "________________________________________________________________________________\n",
            "Epoch  11\n",
            "Saved checkpoint for epoch 11: tf_ckpts/ckpt-11\n",
            "Time taken  9.605168581008911\n",
            "Epoch 11, Loss: 0.908, Accuracy: 67.651, Val Loss: 1.066, Val Accuracy: 59.129\n",
            "________________________________________________________________________________\n",
            "Epoch  12\n",
            "Saved checkpoint for epoch 12: tf_ckpts/ckpt-12\n",
            "Time taken  9.57776165008545\n",
            "Epoch 12, Loss: 0.900, Accuracy: 67.647, Val Loss: 0.992, Val Accuracy: 63.876\n",
            "________________________________________________________________________________\n",
            "Epoch  13\n",
            "Saved checkpoint for epoch 13: tf_ckpts/ckpt-13\n",
            "Time taken  9.52417778968811\n",
            "Epoch 13, Loss: 0.891, Accuracy: 67.701, Val Loss: 1.137, Val Accuracy: 56.693\n",
            "________________________________________________________________________________\n",
            "Epoch  14\n",
            "Saved checkpoint for epoch 14: tf_ckpts/ckpt-14\n",
            "Time taken  9.509803056716919\n",
            "Epoch 14, Loss: 0.883, Accuracy: 67.886, Val Loss: 1.114, Val Accuracy: 56.812\n",
            "________________________________________________________________________________\n",
            "Epoch  15\n",
            "Saved checkpoint for epoch 15: tf_ckpts/ckpt-15\n",
            "Time taken  9.617379426956177\n",
            "Epoch 15, Loss: 0.876, Accuracy: 67.951, Val Loss: 0.951, Val Accuracy: 65.094\n",
            "________________________________________________________________________________\n",
            "Epoch  16\n",
            "Saved checkpoint for epoch 16: tf_ckpts/ckpt-16\n",
            "Time taken  9.826341152191162\n",
            "Epoch 16, Loss: 0.866, Accuracy: 68.296, Val Loss: 0.982, Val Accuracy: 63.182\n",
            "________________________________________________________________________________\n",
            "Epoch  17\n",
            "Saved checkpoint for epoch 17: tf_ckpts/ckpt-17\n",
            "Time taken  9.831774950027466\n",
            "Epoch 17, Loss: 0.863, Accuracy: 68.198, Val Loss: 0.976, Val Accuracy: 63.565\n",
            "________________________________________________________________________________\n",
            "Epoch  18\n",
            "Saved checkpoint for epoch 18: tf_ckpts/ckpt-18\n",
            "Time taken  9.696609735488892\n",
            "Epoch 18, Loss: 0.860, Accuracy: 68.140, Val Loss: 0.911, Val Accuracy: 66.237\n",
            "Validation accuracy increased from 65.784 to 66.237. Saving model weights.\n",
            "________________________________________________________________________________\n",
            "Epoch  19\n",
            "Saved checkpoint for epoch 19: tf_ckpts/ckpt-19\n",
            "Time taken  9.977631330490112\n",
            "Epoch 19, Loss: 0.856, Accuracy: 68.216, Val Loss: 0.937, Val Accuracy: 64.295\n",
            "________________________________________________________________________________\n",
            "Epoch  20\n",
            "Saved checkpoint for epoch 20: tf_ckpts/ckpt-20\n",
            "Time taken  9.622454166412354\n",
            "Epoch 20, Loss: 0.854, Accuracy: 68.211, Val Loss: 0.996, Val Accuracy: 62.386\n",
            "________________________________________________________________________________\n",
            "Epoch  21\n",
            "Saved checkpoint for epoch 21: tf_ckpts/ckpt-21\n",
            "Time taken  9.711670160293579\n",
            "Epoch 21, Loss: 0.850, Accuracy: 68.229, Val Loss: 0.959, Val Accuracy: 65.107\n",
            "________________________________________________________________________________\n",
            "Epoch  22\n",
            "Saved checkpoint for epoch 22: tf_ckpts/ckpt-22\n",
            "Time taken  9.634168863296509\n",
            "Epoch 22, Loss: 0.842, Accuracy: 68.530, Val Loss: 0.921, Val Accuracy: 66.172\n",
            "________________________________________________________________________________\n",
            "Epoch  23\n",
            "Saved checkpoint for epoch 23: tf_ckpts/ckpt-23\n",
            "Time taken  9.820604801177979\n",
            "Epoch 23, Loss: 0.838, Accuracy: 68.589, Val Loss: 0.912, Val Accuracy: 65.397\n",
            "________________________________________________________________________________\n",
            "Epoch  24\n",
            "Saved checkpoint for epoch 24: tf_ckpts/ckpt-24\n",
            "Time taken  9.660136222839355\n",
            "Epoch 24, Loss: 0.837, Accuracy: 68.575, Val Loss: 1.083, Val Accuracy: 58.357\n",
            "________________________________________________________________________________\n",
            "Epoch  25\n",
            "Saved checkpoint for epoch 25: tf_ckpts/ckpt-25\n",
            "Time taken  9.779088497161865\n",
            "Epoch 25, Loss: 0.833, Accuracy: 68.683, Val Loss: 0.923, Val Accuracy: 65.639\n",
            "________________________________________________________________________________\n",
            "Epoch  26\n",
            "Saved checkpoint for epoch 26: tf_ckpts/ckpt-26\n",
            "Time taken  9.614394187927246\n",
            "Epoch 26, Loss: 0.835, Accuracy: 68.618, Val Loss: 0.959, Val Accuracy: 64.534\n",
            "________________________________________________________________________________\n",
            "Epoch  27\n",
            "Saved checkpoint for epoch 27: tf_ckpts/ckpt-27\n",
            "Time taken  9.663967370986938\n",
            "Epoch 27, Loss: 0.830, Accuracy: 68.618, Val Loss: 0.913, Val Accuracy: 65.250\n",
            "________________________________________________________________________________\n",
            "Epoch  28\n",
            "Saved checkpoint for epoch 28: tf_ckpts/ckpt-28\n",
            "Time taken  9.685909748077393\n",
            "Epoch 28, Loss: 0.826, Accuracy: 68.781, Val Loss: 1.009, Val Accuracy: 63.112\n",
            "________________________________________________________________________________\n",
            "Epoch  29\n",
            "Saved checkpoint for epoch 29: tf_ckpts/ckpt-29\n",
            "Time taken  9.794739007949829\n",
            "Epoch 29, Loss: 0.827, Accuracy: 68.792, Val Loss: 0.936, Val Accuracy: 64.531\n",
            "________________________________________________________________________________\n",
            "Epoch  30\n",
            "Saved checkpoint for epoch 30: tf_ckpts/ckpt-30\n",
            "Time taken  9.563223361968994\n",
            "Epoch 30, Loss: 0.822, Accuracy: 68.930, Val Loss: 0.944, Val Accuracy: 65.840\n",
            "________________________________________________________________________________\n",
            "Epoch  31\n",
            "Saved checkpoint for epoch 31: tf_ckpts/ckpt-31\n",
            "Time taken  9.592219352722168\n",
            "Epoch 31, Loss: 0.820, Accuracy: 68.810, Val Loss: 0.926, Val Accuracy: 65.197\n",
            "________________________________________________________________________________\n",
            "Epoch  32\n",
            "Saved checkpoint for epoch 32: tf_ckpts/ckpt-32\n",
            "Time taken  9.757105588912964\n",
            "Epoch 32, Loss: 0.820, Accuracy: 68.966, Val Loss: 0.898, Val Accuracy: 66.594\n",
            "Validation accuracy increased from 66.237 to 66.594. Saving model weights.\n",
            "________________________________________________________________________________\n",
            "Epoch  33\n",
            "Saved checkpoint for epoch 33: tf_ckpts/ckpt-33\n",
            "Time taken  11.38487982749939\n",
            "Epoch 33, Loss: 0.818, Accuracy: 68.899, Val Loss: 0.943, Val Accuracy: 64.198\n",
            "________________________________________________________________________________\n",
            "Epoch  34\n",
            "Saved checkpoint for epoch 34: tf_ckpts/ckpt-34\n",
            "Time taken  9.553881168365479\n",
            "Epoch 34, Loss: 0.822, Accuracy: 68.701, Val Loss: 1.018, Val Accuracy: 60.530\n",
            "________________________________________________________________________________\n",
            "Epoch  35\n",
            "Saved checkpoint for epoch 35: tf_ckpts/ckpt-35\n",
            "Time taken  9.627742290496826\n",
            "Epoch 35, Loss: 0.815, Accuracy: 69.002, Val Loss: 1.010, Val Accuracy: 65.235\n",
            "________________________________________________________________________________\n",
            "Epoch  36\n",
            "Saved checkpoint for epoch 36: tf_ckpts/ckpt-36\n",
            "Time taken  10.271938562393188\n",
            "Epoch 36, Loss: 0.815, Accuracy: 68.913, Val Loss: 0.939, Val Accuracy: 65.247\n",
            "________________________________________________________________________________\n",
            "Epoch  37\n",
            "Saved checkpoint for epoch 37: tf_ckpts/ckpt-37\n",
            "Time taken  9.821139574050903\n",
            "Epoch 37, Loss: 0.812, Accuracy: 69.029, Val Loss: 0.950, Val Accuracy: 63.906\n",
            "________________________________________________________________________________\n",
            "Epoch  38\n",
            "Saved checkpoint for epoch 38: tf_ckpts/ckpt-38\n",
            "Time taken  9.549185991287231\n",
            "Epoch 38, Loss: 0.813, Accuracy: 69.075, Val Loss: 0.963, Val Accuracy: 63.810\n",
            "________________________________________________________________________________\n",
            "Epoch  39\n",
            "Saved checkpoint for epoch 39: tf_ckpts/ckpt-39\n",
            "Time taken  9.75968074798584\n",
            "Epoch 39, Loss: 0.812, Accuracy: 68.931, Val Loss: 1.108, Val Accuracy: 63.061\n",
            "________________________________________________________________________________\n",
            "Epoch  40\n",
            "Saved checkpoint for epoch 40: tf_ckpts/ckpt-40\n",
            "Time taken  9.576231718063354\n",
            "Epoch 40, Loss: 0.806, Accuracy: 69.209, Val Loss: 0.996, Val Accuracy: 66.069\n",
            "________________________________________________________________________________\n",
            "Epoch  41\n",
            "Saved checkpoint for epoch 41: tf_ckpts/ckpt-41\n",
            "Time taken  9.636738061904907\n",
            "Epoch 41, Loss: 0.806, Accuracy: 69.296, Val Loss: 0.922, Val Accuracy: 65.474\n",
            "________________________________________________________________________________\n",
            "Epoch  42\n",
            "Saved checkpoint for epoch 42: tf_ckpts/ckpt-42\n",
            "Time taken  9.805563926696777\n",
            "Epoch 42, Loss: 0.807, Accuracy: 69.049, Val Loss: 0.906, Val Accuracy: 65.389\n",
            "________________________________________________________________________________\n",
            "Epoch  43\n",
            "Saved checkpoint for epoch 43: tf_ckpts/ckpt-43\n",
            "Time taken  9.716373443603516\n",
            "Epoch 43, Loss: 0.807, Accuracy: 69.099, Val Loss: 0.943, Val Accuracy: 64.830\n",
            "________________________________________________________________________________\n",
            "Epoch  44\n",
            "Saved checkpoint for epoch 44: tf_ckpts/ckpt-44\n",
            "Time taken  9.63174057006836\n",
            "Epoch 44, Loss: 0.808, Accuracy: 69.049, Val Loss: 1.002, Val Accuracy: 60.725\n",
            "________________________________________________________________________________\n",
            "Epoch  45\n",
            "Saved checkpoint for epoch 45: tf_ckpts/ckpt-45\n",
            "Time taken  9.792293548583984\n",
            "Epoch 45, Loss: 0.803, Accuracy: 69.259, Val Loss: 0.971, Val Accuracy: 60.166\n",
            "________________________________________________________________________________\n",
            "Epoch  46\n",
            "Saved checkpoint for epoch 46: tf_ckpts/ckpt-46\n",
            "Time taken  9.518763780593872\n",
            "Epoch 46, Loss: 0.808, Accuracy: 68.937, Val Loss: 0.914, Val Accuracy: 64.084\n",
            "________________________________________________________________________________\n",
            "Epoch  47\n",
            "Saved checkpoint for epoch 47: tf_ckpts/ckpt-47\n",
            "Time taken  9.545283794403076\n",
            "Epoch 47, Loss: 0.800, Accuracy: 69.295, Val Loss: 0.975, Val Accuracy: 61.822\n",
            "________________________________________________________________________________\n",
            "Epoch  48\n",
            "Saved checkpoint for epoch 48: tf_ckpts/ckpt-48\n",
            "Time taken  9.598607540130615\n",
            "Epoch 48, Loss: 0.803, Accuracy: 69.274, Val Loss: 1.263, Val Accuracy: 62.330\n",
            "________________________________________________________________________________\n",
            "Epoch  49\n",
            "Saved checkpoint for epoch 49: tf_ckpts/ckpt-49\n",
            "Time taken  9.642390489578247\n",
            "Epoch 49, Loss: 0.803, Accuracy: 69.280, Val Loss: 0.934, Val Accuracy: 63.142\n",
            "________________________________________________________________________________\n",
            "Epoch  50\n",
            "Saved checkpoint for epoch 50: tf_ckpts/ckpt-50\n",
            "Time taken  9.552326202392578\n",
            "Epoch 50, Loss: 0.802, Accuracy: 69.246, Val Loss: 0.936, Val Accuracy: 64.454\n",
            "________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JgIBiGzdWJ4J"
      },
      "source": [
        "display(Image('Pretrained Encoder.png'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NNGN1qPUWJ4J"
      },
      "source": [
        "# Loading the weights of the best model\n",
        "model.load_weights('pspnet_weights-epoch-32.hdf5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3irJ1i9nWJ4K"
      },
      "source": [
        "def predict(model,image_path):\n",
        "    \"\"\"\n",
        "    This function will take the model which is going to be used to predict the image and the image path of \n",
        "    the input image as inputs and predict the mask\n",
        "    It returns the true mask and predicted mask\n",
        "    \"\"\"\n",
        "    # Getting the datapoint\n",
        "    # This function will load the image and its annotation (mask) and return a dictionary.\n",
        "    datapoint = parse_image(image_path)\n",
        "    # Normalizing the resizing the datapoint\n",
        "    input_image,image_mask = load_image_test(datapoint)\n",
        "    # As the model takes input with 4 dimensions (batch_size, rows, columns, channels),\n",
        "    # and the shape of the input image is (rows, columns, channels)\n",
        "    # we will expand the first dimension so we will get the shape as  (1, rows, columns, channels)\n",
        "    img = tf.expand_dims(input_image, 0)\n",
        "    # Predicting the image by passing it to the model\n",
        "    prediction = model(img)\n",
        "    # The model will predict 8 outputs for each pixel\n",
        "    # We have to get the maximum value out of it\n",
        "    prediction = tf.argmax(prediction, axis=-1)\n",
        "    prediction = tf.squeeze(prediction, axis = 0)\n",
        "    pred_mask = tf.expand_dims(prediction, axis=-1)\n",
        "    # Displaying the input image, true mask, predicted mask\n",
        "    #display_sample([input_image, image_mask, pred_mask])\n",
        "    return image_mask, pred_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P0kL2drWJ4K"
      },
      "source": [
        "# Reference -> https://github.com/saisandeepNSS/IDD_SemanticSegmentation\n",
        "\n",
        "def IoU(y_i,y_pred):\n",
        "    # This function calculates the mean Intersection over Union\n",
        "    # Mean IoU = TP/(FN + TP + FP)\n",
        "    # This list will save the IoU of all the classes\n",
        "    IoUs = []\n",
        "    # Defining the number of classes which the model has predicted\n",
        "    n_classes = 8\n",
        "    for c in range(n_classes):\n",
        "        # Calculating the True Positives\n",
        "        TP = np.sum((y_i == c)&(y_pred==c))\n",
        "        # Calculating the False Positives\n",
        "        FP = np.sum((y_i != c)&(y_pred==c))\n",
        "        # Calculating the False Negatives\n",
        "        FN = np.sum((y_i == c)&(y_pred!= c))\n",
        "        # Calculating the IoU for the particular class\n",
        "        IoU = TP/float(TP + FP + FN)\n",
        "        # Printing the outputs\n",
        "        # Uncomment the print statement below when you want to analyze the results for each class\n",
        "        #print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\".format(c,TP,FP,FN,IoU))\n",
        "        # Appending the IoU to the list as it mean needs to be calculated later\n",
        "        if(math.isnan(IoU)):\n",
        "            IoUs.append(0)\n",
        "            continue\n",
        "        IoUs.append(IoU)\n",
        "    # Calculating the mean\n",
        "    mIoU = np.mean(IoUs)\n",
        "    #print(\"_________________\")\n",
        "    #print(\"Mean IoU: {:4.3f}\".format(mIoU))\n",
        "    return mIoU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YsxJxXKiWJ4K"
      },
      "source": [
        "### Validation mIoU for PSPNet with Pretrained Encoder  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59LZSi-pWJ4L"
      },
      "source": [
        "img_val = dataset_path + 'leftImg8bit/val/'\n",
        "val_paths = glob(img_val+'*/*_image.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkWYrykeWJ4L"
      },
      "source": [
        "mIoU = []\n",
        "for path in val_paths:\n",
        "    true_mask, pred_mask = predict(model,path)\n",
        "    mIoU.append(IoU(true_mask, pred_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eGjHZIwBWJ4L",
        "outputId": "4f8935c3-4c80-4798-c95f-cd95a5c69def"
      },
      "source": [
        "print(\"Validation mIoU = \",sum(mIoU)/len(mIoU))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation mIoU =  0.2318319058838307\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C5KXr9KrWJ4M"
      },
      "source": [
        "# Importing PSPNet from existing official models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv_pTXNq_42N"
      },
      "source": [
        "#train_paths = glob(img_val+'*/*_image.jpg')\n",
        "\n",
        "#dataset_path = 'drive/My Drive/idd-lite/idd20k_lite/'\n",
        "#img_train = dataset_path + 'leftImg8bit/train/'\n",
        "#glob(img_train+'*/*_image.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cg6cC3wmCpS9"
      },
      "source": [
        "help shutil.copy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4goO_tnLuNAb"
      },
      "source": [
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "img_train = dataset_path + 'leftImg8bit/train/'\n",
        "train_paths = glob(img_train+'*/*_image.jpg')\n",
        "\n",
        "for i in tqdm(train_paths):\n",
        "    img = i.split('/')[-1]\n",
        "    shutil.copy(i,'dataset_train/'+img)\n",
        "    #shutil.copy(i,'dataset_path/'+img)\n",
        "    mask_path = tf.strings.regex_replace(i, \"leftImg8bit\", \"gtFine\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"_image.jpg\", \"_label.png\")\n",
        "    mask = img.split('_')[0]+'_label.png'\n",
        "    #shutil.copy(mask_path.numpy(),'dataset_train/'+mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OeblsmaAuY2Q",
        "outputId": "d7bcdddc-89c6-409b-887c-61b2c533fbd5"
      },
      "source": [
        "for i in tqdm(val_paths):\n",
        "    img = i.split('/')[-1]\n",
        "    #shutil.copy(i,'dataset_val/'+img)\n",
        "    mask_path = tf.strings.regex_replace(i, \"leftImg8bit\", \"gtFine\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"_image.jpg\", \"_label.png\")\n",
        "    mask = img.split('_')[0]+'_label.png'\n",
        "    #shutil.copy(mask_path.numpy(),'dataset_val/'+mask)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 204/204 [00:00<00:00, 4863.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stOBgVx1tqVm"
      },
      "source": [
        "# here dir_path is the route directory where all the images and segmentation maps are there\n",
        "#train_path = \"dataset_train\"\n",
        "dataset_path = 'drive/My Drive/idd-lite/idd20k_lite/'\n",
        "train_path = \"dataset_path\"\n",
        "X_train = []\n",
        "for i in os.listdir(train_path):\n",
        "    X_train.append(i.split('.')[0])\n",
        "\n",
        "val_path = \"dataset_val\"\n",
        "X_test = []\n",
        "for i in os.listdir(val_path):\n",
        "    X_test.append(i.split('.')[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04dS28l2jbVE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWO-STrTjgQY"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "# This is formatted as code\n",
        "\n",
        "python 3\n",
        "keras >= 2.2.0 or tensorflow >= 1.13\n",
        "keras-applications >= 1.0.7, <=1.0.8\n",
        "image-classifiers == 1.0.*\n",
        "efficientnet == 1.0.*\n",
        "\n",
        "\n",
        "\n",
        "#!pip install q efficientnet==1.0\n",
        "\n",
        "\n",
        "import tensorflow\n",
        "print(tensorflow.__version__)\n",
        "\n",
        "\n",
        "import segmentation_models as sm\n",
        "\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeJCeGIrbuoS"
      },
      "source": [
        "# we are importing the pretrained unet from the segmentation models\n",
        "# https://github.com/qubvel/segmentation_models\n",
        "SM_FRAMEWORK=keras / SM_FRAMEWORK=tf.keras\n",
        "import segmentation_models as sm\n",
        "from segmentation_models import PSPNet\n",
        "sm.set_framework('tf.keras')\n",
        "tf.keras.backend.set_image_data_format('channels_last')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XpTKEnXnbuoU",
        "scrolled": true
      },
      "source": [
        "# loading the unet model and using the resnet 34 and initilized weights with imagenet weights\n",
        "# \"classes\" :different types of classes in the dataset\n",
        "model = PSPNet('resnet34', encoder_weights='imagenet', classes=8, activation='softmax', input_shape=(192,192,3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IhV3Ir5ibuoW"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YL4QZdAbuoZ"
      },
      "source": [
        "# import imgaug.augmenters as iaa\n",
        "# For the assignment choose any 4 augumentation techniques\n",
        "# check the imgaug documentations for more augmentations\n",
        "aug2 = iaa.Fliplr(1)\n",
        "aug3 = iaa.Flipud(1)\n",
        "aug4 = iaa.Emboss(alpha=(1), strength=1)\n",
        "aug5 = iaa.DirectedEdgeDetect(alpha=(0.8), direction=(1.0))\n",
        "aug6 = iaa.Sharpen(alpha=(1.0), lightness=(1.5))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nweraVpDbuoa"
      },
      "source": [
        "def visualize(**images):\n",
        "    n = len(images)\n",
        "    plt.figure(figsize=(16, 5))\n",
        "    for i, (name, image) in enumerate(images.items()):\n",
        "        plt.subplot(1, n, i + 1)\n",
        "        plt.xticks([])\n",
        "        plt.yticks([])\n",
        "        plt.title(' '.join(name.split('_')).title())\n",
        "        if i==1:\n",
        "            plt.imshow(image, cmap='gray', vmax=1, vmin=0)\n",
        "        else:\n",
        "            plt.imshow(image)\n",
        "    plt.show()\n",
        "    \n",
        "def normalize_image(img):\n",
        "    img = img/255\n",
        "    return img\n",
        "\n",
        "class Dataset:\n",
        "    \n",
        "    CLASSES = [0,1,2,3,4,5,6,7]\n",
        "    \n",
        "    def __init__(self, directory, img_files,  classes):\n",
        "        \n",
        "        self.img_ids = img_files\n",
        "        self.images_fps   = [os.path.join(directory, image_id.split('_')[0]+'_image.jpg') for image_id in self.img_ids]\n",
        "        self.masks_fps    = [os.path.join(directory, image_id.split('_')[0]+'_label.png') for image_id in self.img_ids]\n",
        "        self.class_values = [0,1,2,3,4,5,6,7]\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        \n",
        "        # read data\n",
        "        image = cv2.imread(self.images_fps[i], cv2.IMREAD_UNCHANGED)\n",
        "        mask  = cv2.imread(self.masks_fps[i], cv2.IMREAD_UNCHANGED)\n",
        "        image = np.float32(cv2.resize(image,(192,192)))\n",
        "        mask = np.float32(cv2.resize(mask,(192,192)))\n",
        "        mask[mask==255] = 7\n",
        "        image = normalize_image(image)\n",
        "\n",
        "        image_masks = [(mask == v) for v in self.class_values]\n",
        "        image_mask = np.stack(image_masks, axis=-1).astype('float')\n",
        "\n",
        "        a = np.random.uniform()\n",
        "        if a<0.2:\n",
        "            image = aug2.augment_image(image)\n",
        "            image_mask = aug2.augment_image(image_mask)\n",
        "        elif a<0.4:\n",
        "            image = aug3.augment_image(image)\n",
        "            image_mask = aug3.augment_image(image_mask)\n",
        "        elif a<0.6:\n",
        "            image = aug4.augment_image(image)\n",
        "            image_mask = aug4.augment_image(image_mask)\n",
        "        elif a<0.8:\n",
        "            image = aug5.augment_image(image)\n",
        "            image_mask = image_mask\n",
        "        else:\n",
        "            image = aug6.augment_image(image)\n",
        "            image_mask = aug6.augment_image(image_mask)\n",
        "\n",
        "        return image, image_mask\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.img_ids)\n",
        "    \n",
        "    \n",
        "class Dataloder(tf.keras.utils.Sequence):    \n",
        "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
        "        self.dataset = dataset\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.indexes = np.arange(len(dataset))\n",
        "\n",
        "    def __getitem__(self, i):       \n",
        "        # collect batch data\n",
        "        start = i * self.batch_size\n",
        "        stop = (i + 1) * self.batch_size\n",
        "        data = []\n",
        "        for j in range(start, stop):\n",
        "            data.append(self.dataset[j])\n",
        "        \n",
        "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
        "        \n",
        "        return tuple(batch)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.indexes) // self.batch_size\n",
        "    \n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            self.indexes = np.random.permutation(self.indexes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XT3hj1dGbuod"
      },
      "source": [
        "# https://github.com/qubvel/segmentation_models\n",
        "import segmentation_models as sm\n",
        "from segmentation_models.metrics import iou_score\n",
        "from segmentation_models import Unet\n",
        "\n",
        "optim = tf.keras.optimizers.Adam(0.0001)\n",
        "\n",
        "focal_loss = sm.losses.cce_dice_loss\n",
        "\n",
        "# actulally total_loss can be imported directly from library, above example just show you how to manipulate with losses\n",
        "# total_loss = sm.losses.binary_focal_dice_loss \n",
        "# or total_loss = sm.losses.categorical_focal_dice_loss \n",
        "\n",
        "model.compile(optim, focal_loss, metrics=['accuracy',iou_score])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6MdKt4Tbuof"
      },
      "source": [
        "# Dataset for train images\n",
        "CLASSES = ['Drivable', 'Non_Drivable', 'Living_things', 'Vehicles', 'Road_side_objects', 'Far_objects', 'Sky', 'Other']\n",
        "    \n",
        "train_dataset = Dataset(train_path, X_train, classes=CLASSES)\n",
        "test_dataset  = Dataset(val_path, X_test, classes=CLASSES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HDa3vPNMnoZe"
      },
      "source": [
        "train_dataloader = Dataloder(train_dataset, batch_size=16, shuffle=True)\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "print(train_dataloader[0][0].shape)\n",
        "assert train_dataloader[0][0].shape == (16, 192, 192, 3)\n",
        "assert train_dataloader[0][1].shape == (16, 192, 192, 8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eigCK3TZbuoh"
      },
      "source": [
        "history = model.fit_generator(train_dataloader, steps_per_epoch=len(train_dataloader), epochs=50,\\\n",
        "                              validation_data=test_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OxForupXbuoi"
      },
      "source": [
        "# Plot training & validation iou_score values\n",
        "plt.figure(figsize=(30, 5))\n",
        "plt.subplot(121)\n",
        "plt.plot(history.history['iou_score'])\n",
        "plt.plot(history.history['val_iou_score'])\n",
        "plt.title('Model iou_score')\n",
        "plt.ylabel('iou_score')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(122)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIK8bq3Nb9MY"
      },
      "source": [
        "HEIGHT = 192\n",
        "WIDTH = 192\n",
        "\n",
        "def parse_image(img_path):\n",
        "    \"\"\"\n",
        "    Load an image and its annotation (mask) and returning a dictionary.\n",
        "    \"\"\"\n",
        "    # Reading the image\n",
        "    image = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    # For one Image path:\n",
        "    # .../idd20k_lite/leftImg8bit/train/024541_image.jpg\n",
        "    # Its corresponding annotation path is:\n",
        "    # .../idd20k_lite/gtFine/train/024541_label.png\n",
        "    mask_path = tf.strings.regex_replace(img_path, \"leftImg8bit\", \"gtFine\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"_image.jpg\", \"_label.png\")\n",
        "    # Reading the annotation file corresponding the image file\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    # In scene parsing, \"not labeled\" = 255\n",
        "    # But it will mess with our N_CLASS = 7\n",
        "    # Since 255 means the 255th class\n",
        "    # Which doesn't exist\n",
        "    mask = tf.where(mask==255, np.dtype('uint8').type(7), mask)\n",
        "    # Note that we have to convert the new value (7)\n",
        "    # With the same dtype than the tensor itself\n",
        "    return {'image': image, 'segmentation_mask': mask}\n",
        "\n",
        "# Reference -> https://www.tensorflow.org/api_docs/python/tf/cast\n",
        "# Returns a Tensor same shape as given tensor and same type as dtype that is mentioned.\n",
        "\n",
        "def normalize(input_image, input_mask):\n",
        "    \"\"\"\n",
        "    Rescale the pixel values of the images between 0 and 1 compared to [0,255] originally.\n",
        "    \"\"\"\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    return input_image, input_mask\n",
        "\n",
        "def load_image_test(datapoint):\n",
        "    \"\"\"\n",
        "    Normalize and resize a test image and its annotation.\n",
        "    Since this is for the test set, we don't need to apply any data augmentation technique.\n",
        "    \"\"\"\n",
        "    input_image = tf.image.resize(datapoint['image'], (HEIGHT,WIDTH))\n",
        "    input_mask = tf.image.resize(datapoint['segmentation_mask'], (HEIGHT,WIDTH))\n",
        "    input_image, input_mask = normalize(input_image, input_mask)\n",
        "    return input_image, input_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcEcEIvMJDJO"
      },
      "source": [
        "# Reference -> https://github.com/saisandeepNSS/IDD_SemanticSegmentation\n",
        "\n",
        "def IoU(y_i,y_pred):\n",
        "    # This function calculates the mean Intersection over Union\n",
        "    # Mean IoU = TP/(FN + TP + FP)\n",
        "    # This list will save the IoU of all the classes\n",
        "    IoUs = []\n",
        "    # Defining the number of classes which the model has predicted\n",
        "    n_classes = 8\n",
        "    for c in range(n_classes):\n",
        "        # Calculating the True Positives\n",
        "        TP = np.sum((y_i == c)&(y_pred==c))\n",
        "        # Calculating the False Positives\n",
        "        FP = np.sum((y_i != c)&(y_pred==c))\n",
        "        # Calculating the False Negatives\n",
        "        FN = np.sum((y_i == c)&(y_pred!= c))\n",
        "        # Calculating the IoU for the particular class\n",
        "        IoU = TP/float(TP + FP + FN)\n",
        "        # Printing the outputs\n",
        "        # Uncomment the print statement below when you want to analyze the results for each class\n",
        "        #print(\"class {:02.0f}: #TP={:6.0f}, #FP={:6.0f}, #FN={:5.0f}, IoU={:4.3f}\".format(c,TP,FP,FN,IoU))\n",
        "        # Appending the IoU to the list as it mean needs to be calculated later\n",
        "        if(math.isnan(IoU)):\n",
        "            IoUs.append(0)\n",
        "            continue\n",
        "        IoUs.append(IoU)\n",
        "    # Calculating the mean\n",
        "    mIoU = np.mean(IoUs)\n",
        "    #print(\"_________________\")\n",
        "    #print(\"Mean IoU: {:4.3f}\".format(mIoU))\n",
        "    return mIoU"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epCBdc3oJuGU"
      },
      "source": [
        "def predict(model,image_path):\n",
        "    \"\"\"\n",
        "    This function will take the model which is going to be used to predict the image and the image path of \n",
        "    the input image as inputs and predict the mask\n",
        "    It returns the true mask and predicted mask\n",
        "    \"\"\"\n",
        "    # Getting the datapoint\n",
        "    # This function will load the image and its annotation (mask) and return a dictionary.\n",
        "    datapoint = parse_image(image_path)\n",
        "    # Normalizing the resizing the datapoint\n",
        "    input_image,image_mask = load_image_test(datapoint)\n",
        "    # As the model takes input with 4 dimensions (batch_size, rows, columns, channels),\n",
        "    # and the shape of the input image is (rows, columns, channels)\n",
        "    # we will expand the first dimension so we will get the shape as  (1, rows, columns, channels)\n",
        "    img = tf.expand_dims(input_image, 0)\n",
        "    # Predicting the image by passing it to the model\n",
        "    prediction = model.predict_on_batch(img)\n",
        "    # The model will predict 8 outputs for each pixel\n",
        "    # We have to get the maximum value out of it\n",
        "    prediction = tf.argmax(prediction, axis=-1)\n",
        "    prediction = tf.squeeze(prediction, axis = 0)\n",
        "    pred_mask = tf.expand_dims(prediction, axis=-1)\n",
        "    # Displaying the input image, true mask, predicted mask\n",
        "    #display_sample([input_image, image_mask, pred_mask])\n",
        "    return image_mask, pred_mask"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDg-YPNDWJ4S"
      },
      "source": [
        "### Validation mIoU for PSPNet imported model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8O9we200JP3D"
      },
      "source": [
        "img_val = dataset_path + 'leftImg8bit/val/'\n",
        "val_paths = glob(img_val+'*/*_image.jpg')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eTz1GK53JJBF"
      },
      "source": [
        "mIoU = []\n",
        "for path in val_paths:\n",
        "    true_mask, pred_mask = predict(model,path)\n",
        "    mIoU.append(IoU(true_mask, pred_mask))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7ZAZG1Wdc-K"
      },
      "source": [
        "print(\"Validation mIoU Score : \",sum(mIoU)/len(mIoU))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ9cpA1vWJ4U"
      },
      "source": [
        "# Observations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpmLS5QZWJ4U"
      },
      "source": [
        "from prettytable import PrettyTable\n",
        "\n",
        "# Representing results in a table\n",
        "pt = PrettyTable()\n",
        "\n",
        "pt.field_names = [\"Model\", \"Highest Train Accuracy\", \"Highest Validation Accuracy\", \"Validation mIoU\"]\n",
        "pt.add_row([\"PSPNet (from Scratch)\",'89.76 %','80.80 %',0.43338])\n",
        "pt.add_row([\"PSPNet with a Pretrained Encoder\",'69.438 %','66.919 %',0.24952])\n",
        "pt.add_row([\"PSPNet (from official models)\",'89.91 %','83.08 %', 0.36370])\n",
        "print(pt)            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6oWF2ArWJ4U"
      },
      "source": [
        "* The best results are found using PSPNet from Scratch model.\n",
        "* When we train PSPNet using a pretrained encoder, the results fluctuate a lot and the validation mIoU is very low as well.\n",
        "* While using the official model, we get a high validation accuracy, but the validation mIoU score is low."
      ]
    }
  ]
}