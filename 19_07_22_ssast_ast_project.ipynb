{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "19_07_22_ssast_ast_project.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNjLDwFYAwtsWgYeaHB8czW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TIMEdilation584/JP_Loksatta_moving_hearts/blob/master/19_07_22_ssast_ast_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Aec_ZDCTSUW"
      },
      "outputs": [],
      "source": [
        "# pretraining stage\n",
        "# suppose you have an unlabled dataset with avg length of 1024 frames (i.e., 10.24s)\n",
        "input_tdim = 1024\n",
        "# create a 16*16 patch based AST model for pretraining.\n",
        "# note, we don't use patch split overlap in pretraining, so fstride=fshape and tstride=tshape\n",
        "ast_mdl = ASTModel(\n",
        "             fshape=16, tshape=16, fstride=16, tstride=16,\n",
        "             input_fdim=128, input_tdim=input_tdim, model_size='base',\n",
        "             pretrain_stage=True)\n",
        "# # alternatively, create a frame based AST model\n",
        "# ast_mdl = ASTModel(\n",
        "#              fshape=128, tshape=2, fstride=128, tstride=2,\n",
        "#              input_fdim=128, input_tdim=input_tdim, model_size='base',\n",
        "#              pretrain=True)\n",
        "\n",
        "# do pretraining, see src/traintest_mask.py for our full pretraining code\n",
        "# input in shape [batch_size, input_tdim, input_fdim]\n",
        "test_input = torch.zeros([10, input_tdim, 128])\n",
        "# mask 100 patches for both discriminative and generative loss\n",
        "acc, nce_loss = ast_mdl(test_input, task='pretrain_mpc', mask_patch=100)\n",
        "mse_loss = ast_mdl(test_input, task='pretrain_mpg', mask_patch=100)\n",
        "loss = nce_loss + 10 * mse_loss\n",
        "# do back propagate and update the model, etc\n",
        "\n",
        "# after pretraining, save the pretrained model.\n",
        "# the code is designed for Dataparallel model\n",
        "ast_mdl = torch.nn.DataParallel(ast_mdl)\n",
        "torch.save(ast_mdl.state_dict(), './test_mdl.pth')\n",
        "\n",
        "# fine-tuning stage\n",
        "# now you have a labeled dataset you want to finetune AST on\n",
        "# suppose the avg length is 100 frames (1s) and there are 35 classes\n",
        "# the fshape and tshape must be same in pretraining and finetuning\n",
        "# but fstride and tstride can be different in pretraining and finetuning\n",
        "# using smaller strides improves the performance but also increase the computational overhead\n",
        "# set pretrain_stage as False since now is in the finetuning stage\n",
        "# provide the path of the pretrained model you want to load\n",
        "input_tdim = 100  # fine-tuning data length can be different with pretraining data length\n",
        "ast_mdl = ASTModel(label_dim=35,\n",
        "             fshape=16, tshape=16, fstride=10, tstride=10,\n",
        "             input_fdim=128, input_tdim=input_tdim, model_size='base',\n",
        "             pretrain_stage=False, load_pretrained_mdl_path='./test_mdl.pth')\n",
        "# # alternatively, use a frame based AST model\n",
        "# ast_mdl = ASTModel(label_dim=35,\n",
        "#              fshape=128, tshape=2, fstride=128, tstride=1,\n",
        "#              input_fdim=128, input_tdim=input_tdim, model_size='base',\n",
        "#              pretrain_stage=False, load_pretrained_mdl_path='./test_mdl.pth')\n",
        "\n",
        "# do finetuning, see src/traintest.py for our finetuning code\n",
        "test_input = torch.zeros([10, input_tdim, 128])\n",
        "prediction = ast_mdl(test_input, task='ft_avgtok')\n",
        "# output should in shape [batch_size, label_dim]\n",
        "print(prediction.shape)\n",
        "# calculate the loss, do back propagate, etc"
      ]
    }
  ]
}